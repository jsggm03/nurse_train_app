# nurse_train_app.py
import os, io, json, ast, re, time, hashlib, tempfile, random
from glob import glob
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd
from numpy.linalg import norm

import streamlit as st
from streamlit_chat import message
from openai import OpenAI

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)", page_icon="ğŸ©º", layout="wide")

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
client = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = "gpt-4o-mini"                      # ìƒì„±/í‰ê°€/ì½”ì¹­ ê³µìš©
EMBED_OPTIONS = ["text-embedding-3-small", "text-embedding-3-large"]
DEFAULT_EMBED = "text-embedding-3-large"
DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

# â–¶ ê¸°ë³¸ ì—‘ì…€ ìœ„ì¹˜(ë£¨íŠ¸ ë˜ëŠ” /assets)
BASE_DIR = Path(__file__).resolve().parent
XLS_CANDIDATES = [
    BASE_DIR / "ê°„í˜¸ì‚¬êµìœ¡_ì§ˆì˜ì‘ë‹µìë£Œ_ê·¼ë¬´ì§€ë³„.xlsx",
    BASE_DIR / "assets/ê°„í˜¸ì‚¬êµìœ¡_ì§ˆì˜ì‘ë‹µìë£Œ_ê·¼ë¬´ì§€ë³„.xlsx",
]

# =========================
# ìœ í‹¸
# =========================
def md5_of_bytes(b: bytes) -> str:
    m = hashlib.md5(); m.update(b); return m.hexdigest()

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    da, db = norm(a), norm(b)
    return float(np.dot(a, b) / (da * db)) if (da and db) else 0.0

def to_np(e): return np.array(e, dtype=np.float32)

def safe_parse_embedding(x):
    try: return json.loads(x)
    except Exception: return ast.literal_eval(x)

@st.cache_data
def _load_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()

# --- ê·¼ë¬´ì§€ í‘œê¸° í†µì¼ / ë‚˜ìœ ê°’ ì •ë¦¬ ---
WARD_MAP = {
    "ì¼ë°˜ë³‘ë™": "ë³‘ë™ë¶„ë§Œì‹¤", "ë¶„ë§Œì‹¤": "ë³‘ë™ë¶„ë§Œì‹¤", "ë³‘ë™": "ë³‘ë™ë¶„ë§Œì‹¤",
    "ì†Œì•„ê³¼": "ì‹ ìƒì•„ë¶€ì„œ", "ì‹ ìƒì•„": "ì‹ ìƒì•„ë¶€ì„œ", "NICU": "ì‹ ìƒì•„ë¶€ì„œ",
}
BAD_WARD_VALUES = {"", "nan", "none", "null", "na", "n/a", "-", "â€”", "ë¯¸ìƒ"}

def clean_ward(s: str) -> str:
    s = str(s or "").strip()
    return "" if s.lower() in BAD_WARD_VALUES else s

def normalize_ward(s: str) -> str:
    s = clean_ward(s)
    if not s:
        return ""
    s_flat = re.sub(r"\s+", "", s)
    return WARD_MAP.get(s_flat, s)

# ì»¨í…ìŠ¤íŠ¸ ë‚´ [í‚¤] ê°’ ì¶”ì¶œ (í´ë¦¬ë‹ í¬í•¨)
def extract_tag_value(context_text: str, keys: List[str]) -> str:
    text = context_text or ""
    for k in keys:
        m = re.search(rf"\[{re.escape(k)}\]\s*([^|\n]+)", text)
        if m:
            return clean_ward(m.group(1))
    return ""

# ë‹µì•ˆì´ ì„ì—¬ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì œê±°
ANSWER_KEYS = ["í‘œì¤€ì‘ë‹µ", "ì •ë‹µ", "ëª¨ë²”ë‹µì•ˆ", "ë‹µì•ˆ", "answer", "response"]
def strip_answer_from_context(ctx: str, ans: str = "") -> str:
    if not ctx: return ""
    s = str(ctx)
    # [í‘œì¤€ì‘ë‹µ] ... ë˜ëŠ” [ì •ë‹µ] ... ê°™ì€ í•„ë“œ í†µì§¸ë¡œ ì œê±° (íŒŒì´í”„ êµ¬ë¶„ì ê³ ë ¤)
    for k in ANSWER_KEYS:
        s = re.sub(rf"\[\s*{re.escape(k)}\s*\]\s*[^|\n]+(\s*\|\s*)?", "", s, flags=re.IGNORECASE)
    # ë‹µì•ˆ í…ìŠ¤íŠ¸ê°€ ê·¸ëŒ€ë¡œ ë“¤ì–´ê°€ ìˆìœ¼ë©´ ì œê±°
    if ans:
        s = s.replace(str(ans).strip(), "")
    # ì¤‘ë³µëœ êµ¬ë¶„ì/ê³µë°± ì •ë¦¬
    s = re.sub(r"\s*\|\s*\|\s*", " | ", s).strip(" |")
    return s.strip()

# ì •ë‹µ ê³µê°œ ìƒíƒœ ë¦¬ì…‹
def reset_reveal_flags():
    st.session_state["revealed_quiz"] = False
    st.session_state["revealed_coach"] = False

# =========================
# ì„ë² ë”©
# =========================
EMBED_MODEL = DEFAULT_EMBED
EMBED_DIM: Optional[int] = None

def get_embedding(text: str) -> List[float]:
    global EMBED_DIM, EMBED_MODEL
    txt = (text or "").strip()
    if txt:
        resp = client.embeddings.create(model=EMBED_MODEL, input=txt)
        vec = resp.data[0].embedding
        if EMBED_DIM is None:
            EMBED_DIM = len(vec)  # small=1536, large=3072
        return vec
    else:
        if EMBED_DIM is None:
            resp = client.embeddings.create(model=EMBED_MODEL, input="a")
            EMBED_DIM = len(resp.data[0].embedding)
        return [0.0] * EMBED_DIM

# =========================
# ì—‘ì…€ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
# =========================
def guess_columns(df: pd.DataFrame) -> Tuple[List[str], Optional[str]]:
    cols = df.columns.tolist()
    answer_candidates = [c for c in cols if any(k in c for k in ["í‘œì¤€", "ë‹µ", "ëª¨ë²”", "response", "ì •ë‹µ", "answer"])]
    answer_col = answer_candidates[0] if answer_candidates else (cols[0] if cols else None)

    context_cols = []
    for c in cols:
        if c == answer_col: continue
        if df[c].dtype == object:
            text_ratio = (df[c].astype(str).str.len() > 0).mean()
            if text_ratio > 0.3:
                context_cols.append(c)
    if not context_cols:
        context_cols = [c for c in cols if c != answer_col][:3]
    return context_cols, answer_col

def build_context_row(row: pd.Series, context_cols: List[str], answer_col: Optional[str]) -> Dict[str, str]:
    parts = []
    for c in context_cols:
        if c == answer_col:   # ì•ˆì „ì¥ì¹˜: ë‹µì•ˆ ì—´ì´ ì„ì—¬ ìˆìœ¼ë©´ ì œì™¸
            continue
        val = str(row.get(c, "") or "").strip()
        if val:
            parts.append(f"[{c}] {val}")
    context_text = " | ".join(parts) if parts else str(row.to_dict())
    answer_text  = str(row.get(answer_col, "") or "").strip() if answer_col else ""
    # ì»¨í…ìŠ¤íŠ¸ ë‚´ì— ë‹µì•ˆ ë¼ë²¨/ë‚´ìš©ì´ ë“¤ì–´ìˆìœ¼ë©´ ì œê±°
    context_text = strip_answer_from_context(context_text, answer_text)
    return {"context": context_text, "answer": answer_text}

# =========================
# ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸
# =========================
def load_forbidden_sheet(xls_bytes: bytes) -> pd.DataFrame:
    try:
        xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        if "ê¸ˆê¸°í‘œí˜„" not in xl.sheet_names:
            return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])
        df = xl.parse("ê¸ˆê¸°í‘œí˜„").fillna("")
        needed = ["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"]
        for n in needed:
            if n not in df.columns: df[n] = ""
        return df[needed]
    except Exception:
        return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])

def forbidden_as_prompt(df_forb: pd.DataFrame) -> str:
    if df_forb is None or df_forb.empty: return ""
    items = []
    for _, r in df_forb.iterrows():
        items.append(f"- ê¸ˆê¸°: {r['ê¸ˆê¸°í‘œí˜„']} | ì´ìœ : {r['ì´ìœ ']} | ëŒ€ì²´: {r['ëŒ€ì²´ë¬¸êµ¬']}")
    return "ë‹¤ìŒ ê¸ˆê¸° í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì œì‹œëœ ëŒ€ì²´ ë¬¸êµ¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n" + "\n".join(items)

# =========================
# ì„ë² ë”© ìºì‹œ êµ¬ì¶•/ë¡œë“œ (ì—‘ì…€ ê¸°ë°˜)
# =========================
def build_or_load_embeddings_from_excel(
    xls_bytes: bytes,
    sheet_name: Optional[str],
    context_cols: List[str],
    answer_col: Optional[str],
    embed_model_name: str
) -> pd.DataFrame:
    file_md5 = md5_of_bytes(xls_bytes)
    columns_sig = json.dumps({"context": context_cols, "answer": answer_col}, ensure_ascii=False, sort_keys=True)
    cache_name = f"embed__{embed_model_name}__{file_md5}__{(sheet_name or 'active')}__{md5_of_bytes(columns_sig.encode())}.csv"
    cache_path = os.path.join(DATA_DIR, cache_name)

    if os.path.isfile(cache_path):
        st.info(f"ğŸ“¦ ìºì‹œ ë¡œë“œ: {os.path.basename(cache_path)}")
        df = pd.read_csv(cache_path)
        df["embedding"] = df["embedding"].apply(safe_parse_embedding)
        return df

    xl = pd.ExcelFile(io.BytesIO(xls_bytes))
    sheets = [sheet_name] if (sheet_name and sheet_name in xl.sheet_names) else [xl.sheet_names[0]]

    rows = []
    for sh in sheets:
        tdf = xl.parse(sh).fillna("")
        for ridx, row in tdf.iterrows():
            built = build_context_row(row, context_cols, answer_col)
            context, answer = built["context"], built["answer"]
            emb = get_embedding(context)
            rows.append({"sheet": sh, "row_index": ridx, "context": context, "answer": answer, "embedding": emb})
            if (ridx % 20) == 19: time.sleep(0.05)

    df = pd.DataFrame(rows, columns=["sheet","row_index","context","answer","embedding"])
    tmp = df.copy(); tmp["embedding"] = tmp["embedding"].apply(json.dumps)
    tmp.to_csv(cache_path, index=False, encoding="utf-8-sig")
    st.success(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ â†’ {os.path.basename(cache_path)}")
    return df

@st.cache_data(show_spinner=True)
def load_precomputed_embeddings(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["embedding"] = df["embedding"].apply(safe_parse_embedding)
    return df

def pick_precomputed_cache(embed_model: str) -> Optional[str]:
    pattern = os.path.join(DATA_DIR, f"embed__{embed_model}__*.csv")
    candidates = glob(pattern)
    if not candidates:
        return None
    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return candidates[0]

# =========================
# ì¼€ì´ìŠ¤ ì¹´íƒˆë¡œê·¸
# =========================
TITLE_KEYS = ["í‰ê°€í•­ëª©","í•­ëª©","ì£¼ì œ","ì¼€ì´ìŠ¤","ì§ˆë¬¸","ì œëª©","ì¹´í…Œê³ ë¦¬"]

def build_catalog_from_preview(df: pd.DataFrame, answer_col: Optional[str]) -> pd.DataFrame:
    title_col = next((c for c in TITLE_KEYS if c in df.columns), None)
    titles, rows, seen = [], [], set()
    for ridx, row in df.iterrows():
        if title_col and str(row.get(title_col,"")).strip():
            t = str(row[title_col]).strip()
        else:
            base = str(row.get(answer_col,"") or "")[:30] if answer_col else ""
            if not base:
                for c in df.columns:
                    s = str(row.get(c,"") or "").strip()
                    if s:
                        base = s[:30]; break
            t = base or f"Row {ridx}"
        if t in seen: 
            continue
        seen.add(t); titles.append(t); rows.append(ridx)
    return pd.DataFrame({"case_title": titles, "row_index": rows})

def build_catalog_from_embed(df_embed: pd.DataFrame) -> pd.DataFrame:
    titles, rows, seen = [], [], set()
    for _, r in df_embed.iterrows():
        text = r["context"]
        m = re.search(r"\[(í‰ê°€í•­ëª©|í•­ëª©|ì£¼ì œ|ì¼€ì´ìŠ¤|ì§ˆë¬¸|ì œëª©|ì¹´í…Œê³ ë¦¬)\]\s*([^|\n]+)", text)
        if m:
            title = m.group(2).strip()[:40]
        else:
            ans = (r.get("answer") or "")[:40]
            title = ans or (text[:40] if text else f"Row {r['row_index']}")
        if title in seen:
            continue
        seen.add(title); titles.append(title); rows.append(int(r["row_index"]))
    return pd.DataFrame({"case_title": titles, "row_index": rows})

def render_case_shelf(catalog: pd.DataFrame, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", show_all: bool = True, cols_count: int = 4) -> Optional[int]:
    """í•„í„°ëœ ì¹´íƒˆë¡œê·¸ì˜ ëª¨ë“  í•­ëª©ì„ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ (show_all=Trueë©´ ì „ë¶€)."""
    if catalog is None or catalog.empty:
        return None
    st.markdown(f"#### ğŸ“š {label}")
    show = catalog.reset_index(drop=True) if show_all else catalog.head(24).reset_index(drop=True)
    cols = st.columns(cols_count)
    chosen: Optional[int] = None
    for i, row in show.iterrows():
        with cols[i % cols_count]:
            if st.button("ğŸ”¹ " + str(row["case_title"]), key=f"case_{label}_{i}"):
                chosen = int(row["row_index"])
    with st.expander("ì „ì²´ ëª©ë¡ ë³´ê¸° (í‘œ)"):
        st.dataframe(catalog)
    return chosen

def select_case_by_row(df_embed: pd.DataFrame, sheet: str, row_index: int) -> pd.DataFrame:
    sel = df_embed[(df_embed["sheet"]==sheet) & (df_embed["row_index"]==row_index)]
    if len(sel)==0: sel = df_embed[df_embed["row_index"]==row_index]
    if len(sel)==0: sel = df_embed.head(1)
    return sel.head(1).reset_index(drop=True)

# =========================
# ê²€ìƒ‰ & LLM í˜¸ì¶œ
# =========================
def search_top_k(df: pd.DataFrame, query: str, k: int = 3) -> pd.DataFrame:
    q_emb = to_np(get_embedding(query))
    if "_np_emb" not in df.columns:
        df["_np_emb"] = df["embedding"].apply(to_np)
    sims = df["_np_emb"].apply(lambda v: cosine_sim(v, q_emb))
    return df.assign(similarity=sims).sort_values("similarity", ascending=False).head(k).reset_index(drop=True)

def call_llm(messages: List[Dict[str, str]], max_output_tokens: int = 900, temperature: float = 0.3) -> str:
    resp = client.responses.create(
        model=CHAT_MODEL,
        input=messages,
        max_output_tokens=max_output_tokens,
        temperature=temperature,
    )
    try:
        return (resp.output_text or "").strip()
    except Exception:
        try:
            parts = resp.output[0].content
            return "".join([c.text for c in parts if getattr(c, "type", "") == "output_text"]).strip()
        except Exception:
            return "[ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨]"

# =========================
# ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸
# =========================
def make_messages_for_answer(topk: pd.DataFrame, user_query: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    def trim(s: str, n: int = 1000): return s if len(s) <= n else s[:n] + " â€¦"
    docs = []
    for i, r in topk.iterrows():
        docs.append(
            f"[doc {i+1}] sheet={r['sheet']} | row={r['row_index']} | sim={r.get('similarity',1.0):.4f}\n"
            f"ì»¨í…ìŠ¤íŠ¸: {trim(r['context'])}\n"
            f"í‘œì¤€ì‘ë‹µ: {trim(r['answer'])}"
        )
    joined = "\n\n".join(docs)
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ ì§ë¬´ êµìœ¡ìš© í•œêµ­ì–´ ì¡°ì–¸ìì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì™€ í‘œì¤€ì‘ë‹µë§Œ ê·¼ê±°ë¡œ, "
        "í˜„ì¥ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì ˆì°¨/ë¬¸êµ¬/ì£¼ì˜ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©°, í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "")
    )
    user = (
        f"ì§ˆë¬¸: {user_query}\n\n"
        f"ì°¸ê³  ìë£Œ:\n{joined}\n\n"
        "ì¶œë ¥ í˜•ì‹:\n"
        "1) í•µì‹¬ ìš”ì§€ bullet\n2) ë‹¨ê³„/ìš°ì„ ìˆœìœ„\n3) ê¶Œì¥ ë§í•˜ê¸° ì˜ˆì‹œ\n4) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: [doc n], sheet/row"
    )
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_quiz(top1: pd.Series, user_answer: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ êµìœ¡ í‰ê°€ìì…ë‹ˆë‹¤. í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•˜ì„¸ìš”. "
        "í™˜ìì•ˆì „/ì ˆì°¨ ì •í™•ì„±/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì ì ˆì„± ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê¸ˆê¸° í‘œí˜„ì€ ê°ì í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace} ìƒí™©ì…ë‹ˆë‹¤. "
        + (("\n" + forb_prompt) if forb_prompt else "") +
        "\në°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í”¼ë“œë°±í•˜ì„¸ìš”."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{strip_answer_from_context(top1['context'], top1['answer'])}

[í‘œì¤€ì‘ë‹µ]
{top1['answer']}

[í›ˆë ¨ìƒ ë‹µë³€]
{user_answer}

ìš”êµ¬ì‚¬í•­:
- ì¥ë‹¨ì  í”¼ë“œë°±(í•­ëª©ë³„)
- ì ìˆ˜(0~100)ì™€ ê·¼ê±°
- ê°œì„  ì˜ˆì‹œ ë‹µë³€(í˜„ì¥í˜•)
- ë§ˆì§€ë§‰ ì¤„: ê·¼ê±° í‘œê¸°(sheet/row)
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_coach(top1: pd.Series, user_answer: str, workplace: str, tone: str, forb_prompt: str) -> List[Dict[str, str]]:
    context  = strip_answer_from_context((top1["context"] or "").strip(), (top1["answer"] or "").strip())
    standard = (top1["answer"] or "").strip()
    system = (
        "ë‹¹ì‹ ì€ ì„ìƒ í˜„ì¥ì—ì„œ ê°„í˜¸ì‚¬ì˜ í™˜ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ì½”ì¹­í•˜ëŠ” í•œêµ­ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. "
        "í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ í—ˆìš©í•˜ë˜, í™˜ìì•ˆì „ê³¼ ì˜ˆì ˆ(ì¡´ì¹­/ê²½ì²­/ëª…ë£Œì„±)ì„ ìµœìš°ì„  ê¸°ì¤€ìœ¼ë¡œ ì§€ë„í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©° í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "") +
        "\nì¶”ì¸¡ì€ ê¸ˆì§€í•˜ë©° ì œê³µ ìë£Œ ë²”ìœ„ì—ì„œë§Œ ì§€ë„í•©ë‹ˆë‹¤."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{context}

[í‘œì¤€ì‘ë‹µ(ê·¼ê±°)]
{standard}

[í›ˆë ¨ìƒ ì´ˆì•ˆ]
{user_answer}

ìš”êµ¬ì‚¬í•­(í•œêµ­ì–´ë¡œ {tone}):
1) ì˜í•œ ì (1~3ê°œ) â€” ìœ ì§€ ì´ìœ 
2) ê°œì„  í¬ì¸íŠ¸(2~4ê°œ) â€” ì™œ/ì–´ë–»ê²Œ
3) ëª¨ë²” ë‹µì•ˆ(Baseline Script) â€” 2~4ë¬¸ì¥
4) ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸(Variants)
   - ì§§ê³  ì •ì¤‘í•œ(1~2ë¬¸ì¥)
   - ê³µê° ê°•í™”(2~3ë¬¸ì¥)
   - ê¸´ê¸‰/ì•ˆì „ ìš°ì„ (í•„ìš”ì‹œ, 1~2ë¬¸ì¥)
5) ì•ˆì „Â·ì˜ˆì ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸(3~6ê°œ) â€” ë°˜ë“œì‹œ/ê¸ˆê¸° êµ¬ë¶„
6) ì—°ìŠµ í”„ë¡¬í”„íŠ¸(1~2ê°œ)
7) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: sheet={top1['sheet']}, row={top1['row_index']}
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

# =========================
# TTS
# =========================
def synthesize_tts(text: str) -> Optional[str]:
    txt = (text or "").strip()
    if not txt: return None
    try:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tmp_path = Path(tmp.name); tmp.close()
        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts", voice="alloy", input=txt
        ) as resp:
            resp.stream_to_file(tmp_path)
        return str(tmp_path)
    except Exception as e:
        st.warning(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def extract_scripts_from_coaching(coaching_markdown: str) -> Dict[str, str]:
    text = coaching_markdown or ""
    def grab(section_title: str) -> str:
        pat = re.compile(rf"{section_title}.*?(?:\n[-*]\s.*|\n\n.+)", re.IGNORECASE|re.DOTALL)
        m = pat.search(text)
        return m.group(0).strip() if m else ""
    def first_para(s: str) -> str:
        s = s.strip()
        parts = re.split(r"\n\n+", s)
        return parts[0].strip() if parts else s
    return {"baseline": first_para(grab("ëª¨ë²” ë‹µì•ˆ")), "variants": first_para(grab("ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸"))}

# =========================
# ì‚¬ì´ë“œë°”(ê³µí†µ)
# =========================
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", EMBED_OPTIONS, index=EMBED_OPTIONS.index(DEFAULT_EMBED))
    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì§ˆë¬¸(í•™ìŠµ)", "í€´ì¦ˆ(í‰ê°€)", "ì½”ì¹˜(ì§€ë„)"], index=0)

    # í‘œì‹œëŠ” í†µì¼ëœ ëª…ì¹­ìœ¼ë¡œ
    workplace_display = st.selectbox("ê·¼ë¬´ì§€ í”„ë¦¬ì…‹(í†¤)", ["ë³‘ë™ë¶„ë§Œì‹¤", "ì‘ê¸‰ì‹¤", "ìˆ˜ìˆ ì‹¤", "ì™¸ë˜", "ì‹ ìƒì•„ë¶€ì„œ"], index=0)
    workplace = normalize_ward(workplace_display)

    st.caption("ê·¼ë¬´ì§€ì— ë”°ë¼ ì–´íœ˜/í†¤/ìš°ì„ ìˆœìœ„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.")
    st.divider()
    uploaded = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx) â€” ì—…ë¡œë“œ ì—†ìœ¼ë©´ ê¸°ë³¸ íŒŒì¼ ìë™ ì‚¬ìš©", type=["xlsx"])
    sheet_input = st.text_input("ì‚¬ìš©í•  ì‹œíŠ¸ëª…(ë¹„ìš°ë©´ ì²« ì‹œíŠ¸)", value="")
    use_forbidden = st.toggle("ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸(ê¸ˆê¸°í‘œí˜„) ì‚¬ìš©", value=True)

# =========================
# ìƒíƒœ ì´ˆê¸°í™”
# =========================
defaults = {
    "excel_df": None, "last_topk": None, "context_cols": [], "answer_col": None,
    "coaching_text": "", "catalog": None, "active_sheet": None,
    "revealed_quiz": False, "revealed_coach": False,
    "draft_text": "", "case_order": [], "case_pos": -1, "filter_sig": ""
}
for k, v in defaults.items():
    if k not in st.session_state: st.session_state[k] = v

# =========================
# ê¸°ë³¸ ì—‘ì…€ ìë™ ë¡œë“œ
# =========================
if uploaded is None:
    xls_path = next((p for p in XLS_CANDIDATES if p.exists()), XLS_CANDIDATES[0])
    try:
        xls_bytes = _load_bytes(str(xls_path))
        st.info(f"ì—…ë¡œë“œ ì—†ìŒ â†’ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {xls_path.name}")
    except Exception as e:
        st.error(f"ê¸°ë³¸ ì—‘ì…€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. ({e})")
        st.stop()
else:
    xls_bytes = uploaded.getvalue()

# ê¸ˆê¸° ì‹œíŠ¸
forbidden_df = load_forbidden_sheet(xls_bytes) if use_forbidden else pd.DataFrame()
forb_prompt = forbidden_as_prompt(forbidden_df)

# =========================
# ìºì‹œ ì‚¬ìš©(ìˆìœ¼ë©´)
# =========================
precomputed = pick_precomputed_cache(EMBED_MODEL)
if uploaded is None and st.session_state["excel_df"] is None and precomputed:
    st.session_state["excel_df"] = load_precomputed_embeddings(precomputed)
    st.success(f"ğŸ“¦ ì‚¬ì „ ê³„ì‚° ì„ë² ë”© ì‚¬ìš©: {os.path.basename(precomputed)}")

# =========================
# ë¯¸ë¦¬ë³´ê¸° & ì»¬ëŸ¼ ë§¤í•‘
# =========================
if st.session_state["excel_df"] is None:
    try:
        preview_xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        default_sheet = sheet_input or preview_xl.sheet_names[0]
        st.session_state["active_sheet"] = default_sheet
        preview_df = preview_xl.parse(default_sheet).fillna("")
        st.write(f"**ì‹œíŠ¸:** {default_sheet} / **í–‰:** {len(preview_df)} / **ì—´:** {len(preview_df.columns)}")
        st.dataframe(preview_df.head(8))
    except Exception as e:
        st.error(f"ì—‘ì…€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    st.subheader("ğŸ§© ì»¬ëŸ¼ ë§¤í•‘")
    cols = preview_df.columns.tolist()
    if not st.session_state["context_cols"] and not st.session_state["answer_col"]:
        g_ctx, g_ans = guess_columns(preview_df)
        st.session_state["context_cols"] = g_ctx
        st.session_state["answer_col"] = g_ans

    sel_ctx = st.multiselect("ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹  ì—´ë“¤", cols, default=[c for c in st.session_state["context_cols"] if c in cols])
    sel_ans = st.selectbox("í‘œì¤€ì‘ë‹µ(ì •ë‹µ) ì—´", ["<ì„ íƒ ì•ˆ í•¨>"] + cols,
                           index=(0 if (st.session_state["answer_col"] not in cols) else (cols.index(st.session_state["answer_col"]) + 1)))
    st.caption("í‘œì¤€ì‘ë‹µ ì—´ì„ ì§€ì •í•˜ë©´ í‰ê°€/ì½”ì¹˜ í’ˆì§ˆì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")

    if st.button("ì´ ë§¤í•‘ìœ¼ë¡œ ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ"):
        try:
            df_embed = build_or_load_embeddings_from_excel(
                xls_bytes=xls_bytes,
                sheet_name=(sheet_input or None),
                context_cols=sel_ctx if sel_ctx else cols[:3],
                answer_col=(None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans),
                embed_model_name=EMBED_MODEL
            )
            st.session_state["excel_df"] = df_embed
            st.session_state["context_cols"] = sel_ctx if sel_ctx else cols[:3]
            st.session_state["answer_col"] = (None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans)
            st.session_state["active_sheet"] = default_sheet
            st.success("ì„ë² ë”© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ì„ë² ë”© ì¤€ë¹„ ì‹¤íŒ¨: {e}")

df_embed = st.session_state["excel_df"]
if df_embed is None:
    st.info("ë¨¼ì € **ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ**ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    st.stop()

# ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê·¼ë¬´ì§€(ë³‘ë™) ì»¬ëŸ¼ ì¶”ì¶œ + ì •ê·œí™”
if "ward" not in df_embed.columns:
    df_embed["ward"] = df_embed["context"].apply(lambda c: extract_tag_value(c, ["ë³‘ë™","ê·¼ë¬´ì§€","ë¶€ì„œ","ì¹´í…Œê³ ë¦¬"]))
df_embed["ward"] = df_embed["ward"].apply(clean_ward)
df_embed["ward_norm"] = df_embed["ward"].apply(normalize_ward)

# ì¹´íƒˆë¡œê·¸
if uploaded is None or 'preview_df' not in locals():
    st.session_state["catalog"] = build_catalog_from_embed(df_embed)
else:
    st.session_state["catalog"] = build_catalog_from_preview(preview_df, st.session_state["answer_col"])
catalog = st.session_state["catalog"]

st.divider()
st.title("ğŸ©º ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)")

# =========================
# ê³µí†µ: ì¶œì œ/í•„í„° ë¡œì§
# =========================
def get_filtered_catalog(_catalog: pd.DataFrame, ward_choice: str) -> pd.DataFrame:
    if (_catalog is not None) and (not _catalog.empty) and ward_choice and ward_choice != "ì „ì²´":
        idxs = set(df_embed.loc[df_embed["ward_norm"] == ward_choice, "row_index"].astype(int).tolist())
        return _catalog[_catalog["row_index"].isin(list(idxs))].reset_index(drop=True)
    return _catalog

def rebuild_order_if_needed(filtered: pd.DataFrame, shuffle: bool, ward_choice: str, mode_tag: str):
    sig = json.dumps({"ward": ward_choice, "shuffle": shuffle, "mode": mode_tag})
    if st.session_state["filter_sig"] != sig:
        st.session_state["filter_sig"] = sig
        order = filtered["row_index"].astype(int).tolist() if filtered is not None else []
        if shuffle: random.shuffle(order)
        st.session_state["case_order"] = order
        st.session_state["case_pos"] = -1
        st.session_state["last_topk"] = None
        reset_reveal_flags()

def next_case(filtered: pd.DataFrame):
    if filtered is None or filtered.empty: return
    if not st.session_state["case_order"]:
        st.session_state["case_order"] = filtered["row_index"].astype(int).tolist()
    st.session_state["case_pos"] = (st.session_state["case_pos"] + 1) % len(st.session_state["case_order"])
    ridx = st.session_state["case_order"][st.session_state["case_pos"]]
    sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
    st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, ridx)
    reset_reveal_flags()

def random_case(filtered: pd.DataFrame):
    if filtered is None or filtered.empty: return
    ridx = int(filtered.sample(1)["row_index"].iloc[0])
    sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
    st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, ridx)
    reset_reveal_flags()

def ensure_case_selected(filtered: pd.DataFrame):
    if st.session_state["last_topk"] is None and filtered is not None and not filtered.empty:
        random_case(filtered)

def show_case_header(top1: pd.Series, reveal_answer: bool):
    st.markdown("### ğŸ“„ ì¼€ì´ìŠ¤ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ì»¨í…ìŠ¤íŠ¸**")
        st.write(strip_answer_from_context(top1["context"], top1.get("answer","")))  # â† UIì—ì„œ ë‹µì•ˆ ìˆ¨ê¹€
    with c2:
        st.markdown("**í‘œì¤€ì‘ë‹µ**")
        if reveal_answer:
            st.success("ì •ë‹µ ê³µê°œ")
            st.write(top1["answer"])
        else:
            st.info("ì •ë‹µì€ ì œì¶œ í›„ ê³µê°œë©ë‹ˆë‹¤.")

# =========================
# ëª¨ë“œë³„ UI
# =========================
if mode == "ì§ˆë¬¸(í•™ìŠµ)":
    with st.form("ask_form", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'í™˜ì í™•ì¸ ì ˆì°¨ëŠ”?')", "")
        send = st.form_submit_button("Send")
    if send and q.strip():
        topk = search_top_k(df_embed, q.strip(), k=3)
        st.session_state["last_topk"] = topk
        msgs = make_messages_for_answer(topk, q.strip(), workplace, forb_prompt)
        ans = call_llm(msgs)
        message(q.strip(), is_user=True, key="ask_u_"+str(time.time()))
        message(ans, key="ask_b_"+str(time.time()))
    with st.expander("ğŸ” ì‚¬ìš©ëœ ìë£Œ(Top-K)"):
        if st.session_state["last_topk"] is not None:
            st.dataframe(st.session_state["last_topk"][["sheet","row_index","similarity","context","answer"]])

elif mode == "í€´ì¦ˆ(í‰ê°€)":
    # ìœ íš¨í•œ ê·¼ë¬´ì§€ ê°’ë§Œ ì¶”ì¶œ
    _valid = (df_embed["ward_norm"].fillna("").astype(str).str.strip())
    _valid = _valid[~_valid.str.lower().isin(BAD_WARD_VALUES)]
    ward_options = ["ì „ì²´"] + sorted(_valid.unique().tolist())

    opt_col1, opt_col2, opt_col3 = st.columns([2,1,1])
    with opt_col1:
        ward_choice = st.selectbox("ê·¼ë¬´ì§€(ë³‘ë™)ë¡œ í•„í„°", ward_options, index=0, key="ward_quiz")
    with opt_col2:
        btn_next = st.button("ë‹¤ìŒ ë¬¸ì œ")
    with opt_col3:
        btn_rand = st.button("ëœë¤ ì¶œì œ")

    filtered_catalog = get_filtered_catalog(catalog, st.session_state.get("ward_quiz","ì „ì²´"))
    st.caption(f"ê°€ìš© ë¬¸í•­: {0 if filtered_catalog is None else len(filtered_catalog)}ê°œ")

    rebuild_order_if_needed(filtered_catalog, shuffle=False, ward_choice=st.session_state.get("ward_quiz","ì „ì²´"), mode_tag="quiz")

    if btn_next: next_case(filtered_catalog)
    if btn_rand: random_case(filtered_catalog)
    ensure_case_selected(filtered_catalog)

    # âœ… ê·¼ë¬´ì§€ë³„ ëª¨ë“  ë²„íŠ¼ì„ ì „ë¶€ í‘œì‹œ
    chosen = render_case_shelf(filtered_catalog, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", show_all=True, cols_count=4)
    if chosen is not None:
        sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
        st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, chosen)
        reset_reveal_flags()

    if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"])>0:
        top1 = st.session_state["last_topk"].iloc[0]
        show_case_header(top1, reveal_answer=st.session_state["revealed_quiz"])

        st.caption("ì»¨í…ìŠ¤íŠ¸ë§Œ ë³´ê³  ë‹µí•´ë³´ì„¸ìš”. ì œì¶œ í›„ ì •ë‹µì´ ê³µê°œë©ë‹ˆë‹¤.")
        with st.form("quiz_form", clear_on_submit=False):
            user_answer = st.text_area("í›ˆë ¨ìƒ ë‹µë³€", height=180)
            btn_eval = st.form_submit_button("í‰ê°€ ìš”ì²­")
        if btn_eval:
            msgs = make_messages_for_quiz(top1, (user_answer or "").strip(), workplace, forb_prompt)
            feedback = call_llm(msgs)
            st.markdown("### ğŸ§ª í‰ê°€ ê²°ê³¼")
            st.write(feedback)
            st.session_state["revealed_quiz"] = True
            with st.expander("ì •ë‹µ(í‘œì¤€ì‘ë‹µ) ë³´ê¸°", expanded=True):
                st.write(top1["answer"])
    else:
        st.warning("ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì„ë² ë”©ì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")

else:  # ì½”ì¹˜(ì§€ë„)
    _valid = (df_embed["ward_norm"].fillna("").astype(str).str.strip())
    _valid = _valid[~_valid.str.lower().isin(BAD_WARD_VALUES)]
    ward_options = ["ì „ì²´"] + sorted(_valid.unique().tolist())

    opt_col1, opt_col2, opt_col3 = st.columns([2,1,1])
    with opt_col1:
        ward_choice = st.selectbox("ê·¼ë¬´ì§€(ë³‘ë™)ë¡œ í•„í„°", ward_options, index=0, key="ward_coach")
    with opt_col2:
        btn_next = st.button("ë‹¤ìŒ ë¬¸ì œ")
    with opt_col3:
        btn_rand = st.button("ëœë¤ ì¶œì œ")

    filtered_catalog = get_filtered_catalog(catalog, st.session_state.get("ward_coach","ì „ì²´"))
    st.caption(f"ê°€ìš© ë¬¸í•­: {0 if filtered_catalog is None else len(filtered_catalog)}ê°œ")

    rebuild_order_if_needed(filtered_catalog, shuffle=False, ward_choice=st.session_state.get("ward_coach","ì „ì²´"), mode_tag="coach")

    if btn_next: next_case(filtered_catalog)
    if btn_rand: random_case(filtered_catalog)
    ensure_case_selected(filtered_catalog)

    # âœ… ê·¼ë¬´ì§€ë³„ ëª¨ë“  ë²„íŠ¼ì„ ì „ë¶€ í‘œì‹œ
    chosen = render_case_shelf(filtered_catalog, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", show_all=True, cols_count=4)
    if chosen is not None:
        sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
        st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, chosen)
        reset_reveal_flags()

    if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"])>0:
        top1 = st.session_state["last_topk"].iloc[0]
        show_case_header(top1, reveal_answer=st.session_state["revealed_coach"])

        st.caption("í›ˆë ¨ìƒì˜ ì´ˆì•ˆ ë¬¸ì¥ì„ ì½”ì¹­í•©ë‹ˆë‹¤. ì œì¶œ í›„ ì •ë‹µì´ ê³µê°œë©ë‹ˆë‹¤.")
        with st.form("coach_form", clear_on_submit=False):
            tone = st.selectbox("ì½”ì¹­ í†¤", ["ë”°ëœ»í•˜ê³  ì •ì¤‘í•˜ê²Œ","ê°„ê²°í•˜ê³  ë‹¨í˜¸í•˜ê²Œ","ì°¨ë¶„í•˜ê³  ê³µê° ìˆê²Œ"], index=0)
            user_answer = st.text_area("í›ˆë ¨ìƒ ì´ˆì•ˆ(í˜„ì¬ ë§í•˜ë ¤ëŠ” ë¬¸ì¥)", value=st.session_state["draft_text"], height=140, key="draft_area")

            colA, colB = st.columns(2)
            with colA:
                if st.session_state["revealed_coach"]:
                    auto_draft = st.form_submit_button("ì´ˆì•ˆ ìë™ ì œì‹œ")
                else:
                    st.caption("ì´ˆì•ˆ ìë™ ì œì‹œëŠ” ì •ë‹µ ê³µê°œ í›„ ì‚¬ìš© ê°€ëŠ¥")
                    auto_draft = False
            with colB:
                btn_coach = st.form_submit_button("ì½”ì¹­ ë°›ê¸°")

        if auto_draft:
            msgs_draft = [
                {"role":"system","content":f"ê°„í˜¸ì‚¬ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì½”ì¹˜ì…ë‹ˆë‹¤. ê·¼ë¬´ì§€: {workplace}. í‘œì¤€ì‘ë‹µì„ ì°¸ê³ í•´ í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥ ì •ì¤‘í•œ ì•ˆë‚´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”."},
                {"role":"user","content": f"[í‘œì¤€ì‘ë‹µ]\n{top1['answer']}\n\nì¶œë ¥: ê³µì†í•˜ê³  ëª…í™•í•œ 1~2ë¬¸ì¥"}
            ]
            draft_text = call_llm(msgs_draft, max_output_tokens=200, temperature=0.2)
            st.session_state["draft_text"] = draft_text
            st.experimental_rerun()

        if btn_coach:
            base_text = (user_answer or "").strip() or (st.session_state["draft_text"] or "").strip()
            msgs = make_messages_for_coach(top1, base_text, workplace, tone, forb_prompt)
            coaching = call_llm(msgs, max_output_tokens=1200, temperature=0.25)
            st.session_state["coaching_text"] = coaching
            st.markdown("### ğŸ§‘â€ğŸ« ì½”ì¹­ ê²°ê³¼")
            st.write(coaching)

            st.session_state["revealed_coach"] = True
            with st.expander("ì •ë‹µ(í‘œì¤€ì‘ë‹µ) ë³´ê¸°", expanded=True):
                st.write(top1["answer"])

            # --- TTS ---
            scripts = extract_scripts_from_coaching(coaching)
            col1, col2, col3 = st.columns(3)
            with col1:
                if scripts.get("baseline"):
                    if st.button("â–¶ï¸ ëª¨ë²” ë‹µì•ˆ ë“£ê¸°"):
                        mp3 = synthesize_tts(scripts["baseline"])
                        if mp3: st.audio(mp3)
            with col2:
                if scripts.get("variants"):
                    if st.button("â–¶ï¸ ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ë“£ê¸°"):
                        mp3 = synthesize_tts(scripts["variants"])
                        if mp3: st.audio(mp3)
            with col3:
                custom_say = st.text_input("ì›í•˜ëŠ” ë¬¸ì¥ ì§ì ‘ ë“£ê¸°(ì„ íƒ)", value="")
                if st.button("â–¶ï¸ ìœ„ ë¬¸ì¥ ë“£ê¸°") and custom_say.strip():
                    mp3 = synthesize_tts(custom_say.strip())
                    if mp3: st.audio(mp3)

        # ì¬ì½”ì¹­
        if st.session_state["coaching_text"]:
            st.divider()
            st.markdown("### âœï¸ ë‹¤ì‹œ ì¨ë³´ê¸° â†’ ì¬ì½”ì¹­")
            revised = st.text_area("ìˆ˜ì •ì•ˆ(ì½”ì¹­ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ì‘ì„±)", height=140, key="revised_text")
            if st.button("ë‹¤ì‹œ ì½”ì¹­"):
                msgs2 = make_messages_for_coach(top1, (revised or "").strip(), workplace, tone, forb_prompt)
                coaching2 = call_llm(msgs2, max_output_tokens=1200, temperature=0.25)
                st.session_state["coaching_text"] = coaching2
                st.markdown("### ğŸ§‘â€ğŸ« ì¬ì½”ì¹­ ê²°ê³¼")
                st.write(coaching2)
    else:
        st.warning("ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì„ë² ë”©ì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")
