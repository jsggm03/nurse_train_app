# nurse_train_app.py
import os, io, json, ast, re, time, hashlib, tempfile
import numpy as np
import pandas as pd
from numpy.linalg import norm
from typing import List, Dict, Optional, Tuple

import streamlit as st
from streamlit_chat import message
from openai import OpenAI

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)", page_icon="ğŸ©º", layout="wide")

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
client = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = "gpt-4o-mini"  # ìƒì„±/í‰ê°€/ì½”ì¹­ ê³µìš©
EMBED_OPTIONS = ["text-embedding-3-small", "text-embedding-3-large"]
DEFAULT_EMBED = "text-embedding-3-large"

DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

# =========================
# ìœ í‹¸
# =========================
def md5_of_bytes(b: bytes) -> str:
    m = hashlib.md5(); m.update(b); return m.hexdigest()

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    da, db = norm(a), norm(b)
    return float(np.dot(a, b) / (da * db)) if (da and db) else 0.0

def to_np(e): return np.array(e, dtype=np.float32)

def safe_parse_embedding(x):
    try: return json.loads(x)
    except Exception: return ast.literal_eval(x)

# =========================
# ì„ë² ë”©(ìë™ ì°¨ì› ê°ì§€)
# =========================
EMBED_MODEL = DEFAULT_EMBED
EMBED_DIM: Optional[int] = None

def get_embedding(text: str) -> List[float]:
    global EMBED_DIM, EMBED_MODEL
    txt = (text or "").strip()
    if txt:
        resp = client.embeddings.create(model=EMBED_MODEL, input=txt)
        vec = resp.data[0].embedding
        if EMBED_DIM is None:
            EMBED_DIM = len(vec)  # small=1536, large=3072
        return vec
    else:
        if EMBED_DIM is None:
            resp = client.embeddings.create(model=EMBED_MODEL, input="a")
            EMBED_DIM = len(resp.data[0].embedding)
        return [0.0] * EMBED_DIM

# =========================
# ì—‘ì…€ ë¡œë”©/ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
# =========================
def guess_columns(df: pd.DataFrame) -> Tuple[List[str], Optional[str]]:
    cols = df.columns.tolist()
    answer_candidates = [c for c in cols if any(k in c for k in ["í‘œì¤€", "ë‹µ", "ëª¨ë²”", "response", "ì •ë‹µ", "answer"])]
    answer_col = answer_candidates[0] if answer_candidates else (cols[0] if cols else None)

    context_cols = []
    for c in cols:
        if c == answer_col: continue
        if df[c].dtype == object:
            text_ratio = (df[c].astype(str).str.len() > 0).mean()
            if text_ratio > 0.3:
                context_cols.append(c)
    if not context_cols:
        context_cols = [c for c in cols if c != answer_col][:3]
    return context_cols, answer_col

def build_context_row(row: pd.Series, context_cols: List[str], answer_col: Optional[str]) -> Dict[str, str]:
    parts = []
    for c in context_cols:
        val = str(row.get(c, "") or "").strip()
        if val:
            parts.append(f"[{c}] {val}")
    context_text = " | ".join(parts) if parts else str(row.to_dict())
    answer_text = str(row.get(answer_col, "") or "").strip() if answer_col else ""
    return {"context": context_text, "answer": answer_text}

# =========================
# ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸ ë¡œë“œ (ì„ íƒ)
# ì‹œíŠ¸ëª…: ê¸ˆê¸°í‘œí˜„ / ì—´: ê¸ˆê¸°í‘œí˜„, ì´ìœ , ëŒ€ì²´ë¬¸êµ¬
# =========================
def load_forbidden_sheet(xls_bytes: bytes) -> pd.DataFrame:
    try:
        xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        if "ê¸ˆê¸°í‘œí˜„" not in xl.sheet_names:
            return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])
        df = xl.parse("ê¸ˆê¸°í‘œí˜„").fillna("")
        needed = ["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"]
        for n in needed:
            if n not in df.columns: df[n] = ""
        return df[needed]
    except Exception:
        return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])

def forbidden_as_prompt(df_forb: pd.DataFrame) -> str:
    if df_forb is None or df_forb.empty: return ""
    items = []
    for _, r in df_forb.iterrows():
        items.append(f"- ê¸ˆê¸°: {r['ê¸ˆê¸°í‘œí˜„']} | ì´ìœ : {r['ì´ìœ ']} | ëŒ€ì²´: {r['ëŒ€ì²´ë¬¸êµ¬']}")
    return "ë‹¤ìŒ ê¸ˆê¸° í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì œì‹œëœ ëŒ€ì²´ ë¬¸êµ¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n" + "\n".join(items)

# =========================
# ì„ë² ë”© ìºì‹œ êµ¬ì¶•/ë¡œë“œ (ì—‘ì…€ ê¸°ë°˜)
# =========================
def build_or_load_embeddings_from_excel(
    xls_bytes: bytes,
    sheet_name: Optional[str],
    context_cols: List[str],
    answer_col: Optional[str],
    embed_model_name: str
) -> pd.DataFrame:
    file_md5 = md5_of_bytes(xls_bytes)
    columns_sig = json.dumps({"context": context_cols, "answer": answer_col}, ensure_ascii=False, sort_keys=True)
    cache_name = f"embed__{embed_model_name}__{file_md5}__{(sheet_name or 'active')}__{md5_of_bytes(columns_sig.encode())}.csv"
    cache_path = os.path.join(DATA_DIR, cache_name)

    if os.path.isfile(cache_path):
        st.info(f"ğŸ“¦ ìºì‹œ ë¡œë“œ: {os.path.basename(cache_path)}")
        df = pd.read_csv(cache_path)
        df["embedding"] = df["embedding"].apply(safe_parse_embedding)
        return df

    xl = pd.ExcelFile(io.BytesIO(xls_bytes))
    if sheet_name and sheet_name in xl.sheet_names: sheets = [sheet_name]
    else: sheets = [xl.sheet_names[0]]

    rows = []
    for sh in sheets:
        tdf = xl.parse(sh).fillna("")
        for ridx, row in tdf.iterrows():
            built = build_context_row(row, context_cols, answer_col)
            context, answer = built["context"], built["answer"]
            emb = get_embedding(context)
            rows.append({"sheet": sh, "row_index": ridx, "context": context, "answer": answer, "embedding": emb})
            if (ridx % 20) == 19: time.sleep(0.05)

    df = pd.DataFrame(rows, columns=["sheet","row_index","context","answer","embedding"])
    tmp = df.copy(); tmp["embedding"] = tmp["embedding"].apply(json.dumps)
    tmp.to_csv(cache_path, index=False, encoding="utf-8-sig")
    st.success(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ â†’ {os.path.basename(cache_path)}")
    return df

# =========================
# ê²€ìƒ‰ & ê³µìš© LLM í˜¸ì¶œ
# =========================
def search_top_k(df: pd.DataFrame, query: str, k: int = 3) -> pd.DataFrame:
    q_emb = to_np(get_embedding(query))
    if "_np_emb" not in df.columns:
        df["_np_emb"] = df["embedding"].apply(to_np)
    sims = df["_np_emb"].apply(lambda v: cosine_sim(v, q_emb))
    return df.assign(similarity=sims).sort_values("similarity", ascending=False).head(k).reset_index(drop=True)

def call_llm(messages: List[Dict[str, str]], max_output_tokens: int = 900, temperature: float = 0.3) -> str:
    resp = client.responses.create(
        model=CHAT_MODEL,
        input=messages,
        max_output_tokens=max_output_tokens,
        temperature=temperature,
    )
    try:
        parts = resp.output[0].content
        return "".join([c.text for c in parts if getattr(c, "type", "") == "output_text"]).strip() or "[ëª¨ë¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤]"
    except Exception:
        return "[ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨]"

# =========================
# ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸
# =========================
def make_messages_for_answer(topk: pd.DataFrame, user_query: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    def trim(s: str, n: int = 1000): return s if len(s) <= n else s[:n] + " â€¦"
    docs = []
    for i, r in topk.iterrows():
        docs.append(
            f"[doc {i+1}] sheet={r['sheet']} | row={r['row_index']} | sim={r['similarity']:.4f}\n"
            f"ì»¨í…ìŠ¤íŠ¸: {trim(r['context'])}\n"
            f"í‘œì¤€ì‘ë‹µ: {trim(r['answer'])}"
        )
    joined = "\n\n".join(docs)
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ ì§ë¬´ êµìœ¡ìš© í•œêµ­ì–´ ì¡°ì–¸ìì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì™€ í‘œì¤€ì‘ë‹µë§Œ ê·¼ê±°ë¡œ, "
        "í˜„ì¥ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì ˆì°¨/ë¬¸êµ¬/ì£¼ì˜ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©°, í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "")
    )
    user = (
        f"ì§ˆë¬¸: {user_query}\n\n"
        f"ì°¸ê³  ìë£Œ:\n{joined}\n\n"
        "ì¶œë ¥ í˜•ì‹:\n"
        "1) í•µì‹¬ ìš”ì§€ bullet\n2) ë‹¨ê³„/ìš°ì„ ìˆœìœ„\n3) ê¶Œì¥ ë§í•˜ê¸° ì˜ˆì‹œ\n4) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: [doc n], sheet/row"
    )
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_quiz(top1: pd.Series, user_answer: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ êµìœ¡ í‰ê°€ìì…ë‹ˆë‹¤. í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•˜ì„¸ìš”. "
        "í™˜ìì•ˆì „/ì ˆì°¨ ì •í™•ì„±/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì ì ˆì„± ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê¸ˆê¸° í‘œí˜„ì€ ê°ì í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace} ìƒí™©ì…ë‹ˆë‹¤. "
        + (("\n" + forb_prompt) if forb_prompt else "") +
        "\në°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í”¼ë“œë°±í•˜ì„¸ìš”."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{top1['context']}

[í‘œì¤€ì‘ë‹µ]
{top1['answer']}

[í›ˆë ¨ìƒ ë‹µë³€]
{user_answer}

ìš”êµ¬ì‚¬í•­:
- ì¥ë‹¨ì  í”¼ë“œë°±(í•­ëª©ë³„)
- ì ìˆ˜(0~100)ì™€ ê·¼ê±°
- ê°œì„  ì˜ˆì‹œ ë‹µë³€(í˜„ì¥í˜•)
- ë§ˆì§€ë§‰ ì¤„: ê·¼ê±° í‘œê¸°(sheet/row)
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_coach(top1: pd.Series, user_answer: str, workplace: str, tone: str, forb_prompt: str) -> List[Dict[str, str]]:
    context = (top1["context"] or "").strip()
    standard = (top1["answer"] or "").strip()
    system = (
        "ë‹¹ì‹ ì€ ì„ìƒ í˜„ì¥ì—ì„œ ê°„í˜¸ì‚¬ì˜ í™˜ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ì½”ì¹­í•˜ëŠ” í•œêµ­ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. "
        "í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ í—ˆìš©í•˜ë˜, í™˜ìì•ˆì „ê³¼ ì˜ˆì ˆ(ì¡´ì¹­/ê²½ì²­/ëª…ë£Œì„±)ì„ ìµœìš°ì„  ê¸°ì¤€ìœ¼ë¡œ ì§€ë„í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©° í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "") +
        "\nì¶”ì¸¡ì€ ê¸ˆì§€í•˜ë©° ì œê³µ ìë£Œ ë²”ìœ„ì—ì„œë§Œ ì§€ë„í•©ë‹ˆë‹¤."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{context}

[í‘œì¤€ì‘ë‹µ(ê·¼ê±°)]
{standard}

[í›ˆë ¨ìƒ ì´ˆì•ˆ]
{user_answer}

ìš”êµ¬ì‚¬í•­(í•œêµ­ì–´ë¡œ {tone}):
1) ì˜í•œ ì (1~3ê°œ) â€” ìœ ì§€ ì´ìœ 
2) ê°œì„  í¬ì¸íŠ¸(2~4ê°œ) â€” ì™œ/ì–´ë–»ê²Œ
3) ëª¨ë²” ë‹µì•ˆ(Baseline Script) â€” 2~4ë¬¸ì¥
4) ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸(Variants)
   - ì§§ê³  ì •ì¤‘í•œ(1~2ë¬¸ì¥)
   - ê³µê° ê°•í™”(2~3ë¬¸ì¥)
   - ê¸´ê¸‰/ì•ˆì „ ìš°ì„ (í•„ìš”ì‹œ, 1~2ë¬¸ì¥)
5) ì•ˆì „Â·ì˜ˆì ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸(3~6ê°œ) â€” ë°˜ë“œì‹œ/ê¸ˆê¸° êµ¬ë¶„
6) ì—°ìŠµ í”„ë¡¬í”„íŠ¸(1~2ê°œ)
7) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: sheet={top1['sheet']}, row={top1['row_index']}
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

# =========================
# TTS (ëª¨ë²”/ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ë‚­ë…)
# =========================
def synthesize_tts(text: str) -> Optional[str]:
    txt = (text or "").strip()
    if not txt: return None
    try:
        speech = client.audio.speech.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=txt
        )
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tmp.write(speech.read())  # SDKê°€ bytes-like ì œê³µ
        tmp.flush(); tmp.close()
        return tmp.name
    except Exception as e:
        st.warning(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def extract_scripts_from_coaching(coaching_markdown: str) -> Dict[str, str]:
    """
    ì½”ì¹­ ê²°ê³¼ í…ìŠ¤íŠ¸ì—ì„œ 'ëª¨ë²” ë‹µì•ˆ', 'ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸' ì„¹ì…˜ì„ ëŸ¬í”„í•˜ê²Œ ì¶”ì¶œ.
    ë§ˆí¬ë‹¤ìš´ í—¤ë”/ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì •í•œ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±.
    """
    text = coaching_markdown
    def grab(section_title: str) -> str:
        pat = re.compile(rf"{section_title}.*?(?:\n[-*]\s.*|\n\n.+)", re.IGNORECASE|re.DOTALL)
        m = pat.search(text)
        if not m: return ""
        block = m.group(0)
        # ë‹¤ìŒ í° ì„¹ì…˜ ì‹œì‘ ì „ê¹Œì§€
        nxt = re.split(r"\n#{1,3}\s|\n\d\)\s|\n[ê°€-í£]+\)", block)[0]
        return nxt.strip()
    baseline = grab("ëª¨ë²” ë‹µì•ˆ")
    variants = grab("ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸")
    # ë” ê¹”ë”í•˜ê²Œ: ì²« ë¬¸ë‹¨ë§Œ
    def first_para(s: str) -> str:
        s = s.strip()
        parts = re.split(r"\n\n+", s)
        return parts[0].strip() if parts else s
    return {
        "baseline": first_para(baseline),
        "variants": first_para(variants)
    }

# =========================
# ì‚¬ì´ë“œë°”
# =========================
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", EMBED_OPTIONS, index=EMBED_OPTIONS.index(DEFAULT_EMBED))
    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì§ˆë¬¸(í•™ìŠµ)", "í€´ì¦ˆ(í‰ê°€)", "ì½”ì¹˜(ì§€ë„)"], index=0)
    workplace = st.selectbox("ê·¼ë¬´ì§€ í”„ë¦¬ì…‹", ["ì¼ë°˜ë³‘ë™", "ì‘ê¸‰ì‹¤", "ìˆ˜ìˆ ì‹¤", "ì™¸ë˜", "ì†Œì•„ê³¼"], index=0)
    st.caption("ê·¼ë¬´ì§€ì— ë”°ë¼ ì–´íœ˜/í†¤/ìš°ì„ ìˆœìœ„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.")
    st.divider()
    uploaded = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])
    sheet_input = st.text_input("ì§ˆë¬¸/í‰ê°€ìš© ì‹œíŠ¸ëª…(ë¹„ìš°ë©´ ì²« ì‹œíŠ¸)", value="")
    use_forbidden = st.toggle("ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸(ê¸ˆê¸°í‘œí˜„) ì‚¬ìš©", value=True)
    st.caption("ì‹œíŠ¸ëª…: 'ê¸ˆê¸°í‘œí˜„' / ì—´: ê¸ˆê¸°í‘œí˜„, ì´ìœ , ëŒ€ì²´ë¬¸êµ¬")

# =========================
# ìƒíƒœ ì´ˆê¸°í™”
# =========================
for k, v in {
    "excel_df": None, "last_topk": None, "context_cols": [], "answer_col": None,
    "coaching_text": ""
}.items():
    if k not in st.session_state: st.session_state[k] = v

# =========================
# ë³¸ë¬¸
# =========================
st.title("ğŸ©º ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)")

if uploaded is None:
    st.info("ì™¼ìª½ì—ì„œ ì—‘ì…€(.xlsx)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

xls_bytes = uploaded.getvalue()

# ë¯¸ë¦¬ë³´ê¸°
try:
    preview_xl = pd.ExcelFile(io.BytesIO(xls_bytes))
    default_sheet = sheet_input or preview_xl.sheet_names[0]
    preview_df = preview_xl.parse(default_sheet).fillna("")
    st.write(f"**ì‹œíŠ¸:** {default_sheet} / **í–‰:** {len(preview_df)} / **ì—´:** {len(preview_df.columns)}")
    st.dataframe(preview_df.head(8))
except Exception as e:
    st.error(f"ì—‘ì…€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
    st.stop()

# ê¸ˆê¸° ì‹œíŠ¸
forbidden_df = load_forbidden_sheet(xls_bytes) if use_forbidden else pd.DataFrame()
forb_prompt = forbidden_as_prompt(forbidden_df)

# ì»¬ëŸ¼ ë§¤í•‘
st.subheader("ğŸ§© ì»¬ëŸ¼ ë§¤í•‘")
cols = preview_df.columns.tolist()
if not st.session_state["context_cols"] and not st.session_state["answer_col"]:
    g_ctx, g_ans = guess_columns(preview_df)
    st.session_state["context_cols"] = g_ctx
    st.session_state["answer_col"] = g_ans

sel_ctx = st.multiselect("ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹  ì—´ë“¤", cols, default=[c for c in st.session_state["context_cols"] if c in cols])
sel_ans = st.selectbox("í‘œì¤€ì‘ë‹µ(ì •ë‹µ) ì—´", ["<ì„ íƒ ì•ˆ í•¨>"] + cols,
                       index=(0 if (st.session_state["answer_col"] not in cols) else (cols.index(st.session_state["answer_col"]) + 1)))
st.caption("í‘œì¤€ì‘ë‹µ ì—´ì„ ì§€ì •í•˜ë©´ í‰ê°€/ì½”ì¹˜ í’ˆì§ˆì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")

if st.button("ì´ ë§¤í•‘ìœ¼ë¡œ ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ"):
    try:
        st.session_state["excel_df"] = build_or_load_embeddings_from_excel(
            xls_bytes=xls_bytes,
            sheet_name=(sheet_input or None),
            context_cols=sel_ctx if sel_ctx else cols[:3],
            answer_col=(None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans),
            embed_model_name=EMBED_MODEL
        )
        st.session_state["context_cols"] = sel_ctx if sel_ctx else cols[:3]
        st.session_state["answer_col"] = (None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans)
        st.success("ì„ë² ë”© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
    except Exception as e:
        st.error(f"ì„ë² ë”© ì¤€ë¹„ ì‹¤íŒ¨: {e}")

df_embed = st.session_state["excel_df"]
if df_embed is None:
    st.info("ë¨¼ì € **ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ**ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    st.stop()

st.divider()

# =========================
# ëª¨ë“œë³„ UI
# =========================
if mode == "ì§ˆë¬¸(í•™ìŠµ)":
    with st.form("ask_form", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'í™˜ì í™•ì¸ ì ˆì°¨ëŠ”?')", "")
        send = st.form_submit_button("Send")
    if send and q.strip():
        topk = search_top_k(df_embed, q.strip(), k=3)
        st.session_state["last_topk"] = topk
        msgs = make_messages_for_answer(topk, q.strip(), workplace, forb_prompt)
        ans = call_llm(msgs)
        message(q.strip(), is_user=True, key="ask_u_"+str(time.time()))
        message(ans, key="ask_b_"+str(time.time()))
    with st.expander("ğŸ” ì‚¬ìš©ëœ ìë£Œ(Top-K)"):
        if st.session_state["last_topk"] is not None:
            st.dataframe(st.session_state["last_topk"][["sheet","row_index","similarity","context","answer"]])

elif mode == "í€´ì¦ˆ(í‰ê°€)":
    st.caption("ë°ì´í„°ì—ì„œ ìƒìœ„ ìœ ì‚¬ í•­ëª© 1ê°œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©ìì˜ ë‹µë³€ì„ í‰ê°€í•©ë‹ˆë‹¤.")
    with st.form("quiz_form", clear_on_submit=False):
        case_query = st.text_input("ì¼€ì´ìŠ¤ í‚¤ì›Œë“œ(ì˜ˆ: ë‚™ìƒ ì˜ˆë°©, í™˜ìí™•ì¸ ë“±)", "")
        user_answer = st.text_area("í›ˆë ¨ìƒ ë‹µë³€", height=180)
        btn_find = st.form_submit_button("ì¼€ì´ìŠ¤ ì°¾ê¸°")
        btn_eval = st.form_submit_button("í‰ê°€ ìš”ì²­")
    if btn_find and case_query.strip():
        topk = search_top_k(df_embed, case_query.strip(), k=1)
        st.session_state["last_topk"] = topk
        st.success("ì¼€ì´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì»¨í…ìŠ¤íŠ¸/í‘œì¤€ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
    if btn_eval:
        if st.session_state["last_topk"] is None or len(st.session_state["last_topk"]) == 0:
            st.warning("ë¨¼ì € 'ì¼€ì´ìŠ¤ ì°¾ê¸°'ë¡œ í‰ê°€ ê¸°ì¤€ì„ ì„ íƒí•˜ì„¸ìš”.")
        elif not user_answer.strip():
            st.warning("í›ˆë ¨ìƒ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            top1 = st.session_state["last_topk"].iloc[0]
            msgs = make_messages_for_quiz(top1, user_answer.strip(), workplace, forb_prompt)
            feedback = call_llm(msgs)
            st.markdown("### ğŸ§ª í‰ê°€ ê²°ê³¼")
            st.write(feedback)
    with st.expander("ğŸ“„ í˜„ì¬ ì„ íƒëœ ì¼€ì´ìŠ¤(Top-1)"):
        if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"]) > 0:
            top1 = st.session_state["last_topk"].iloc[0]
            st.write(f"**sheet:** {top1['sheet']} / **row:** {top1['row_index']} / **sim:** {top1['similarity']:.4f}")
            st.markdown("**ì»¨í…ìŠ¤íŠ¸**"); st.write(top1["context"])
            st.markdown("**í‘œì¤€ì‘ë‹µ**"); st.write(top1["answer"])

else:  # ì½”ì¹˜(ì§€ë„)
    st.caption("í›ˆë ¨ìƒì˜ ì´ˆì•ˆ ë¬¸ì¥ì„ ì½”ì¹­í•˜ì—¬ ë” ì˜ˆì˜ ë°”ë¥´ê³  ì•ˆì „í•œ ë¬¸ì¥ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.")
    with st.form("coach_form", clear_on_submit=False):
        case_query = st.text_input("ì¼€ì´ìŠ¤ í‚¤ì›Œë“œ(ì˜ˆ: í™˜ìí™•ì¸, ë‚™ìƒ ì˜ˆë°©, íˆ¬ì•½ ì „ í™•ì¸ ë“±)", "")
        user_answer = st.text_area("í›ˆë ¨ìƒ ì´ˆì•ˆ(í˜„ì¬ ë§í•˜ë ¤ëŠ” ë¬¸ì¥)", height=160)
        tone = st.selectbox("ì½”ì¹­ í†¤", ["ë”°ëœ»í•˜ê³  ì •ì¤‘í•˜ê²Œ","ê°„ê²°í•˜ê³  ë‹¨í˜¸í•˜ê²Œ","ì°¨ë¶„í•˜ê³  ê³µê° ìˆê²Œ"], index=0)
        btn_find = st.form_submit_button("ì¼€ì´ìŠ¤ ì°¾ê¸°")
        btn_coach = st.form_submit_button("ì½”ì¹­ ë°›ê¸°")
    if btn_find and case_query.strip():
        topk = search_top_k(df_embed, case_query.strip(), k=1)
        st.session_state["last_topk"] = topk
        st.success("ì¼€ì´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì»¨í…ìŠ¤íŠ¸/í‘œì¤€ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
    if btn_coach:
        if st.session_state["last_topk"] is None or len(st.session_state["last_topk"]) == 0:
            st.warning("ë¨¼ì € 'ì¼€ì´ìŠ¤ ì°¾ê¸°'ë¡œ ì½”ì¹­ ê¸°ì¤€ì„ ì„ íƒí•˜ì„¸ìš”.")
        elif not user_answer.strip():
            st.warning("í›ˆë ¨ìƒ ì´ˆì•ˆì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            top1 = st.session_state["last_topk"].iloc[0]
            msgs = make_messages_for_coach(top1, user_answer.strip(), workplace, tone, forb_prompt)
            coaching = call_llm(msgs, max_output_tokens=1200, temperature=0.25)
            st.session_state["coaching_text"] = coaching
            st.markdown("### ğŸ§‘â€ğŸ« ì½”ì¹­ ê²°ê³¼")
            st.write(coaching)

            # --- TTS: ëª¨ë²”/ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ & ì¬ìƒ ---
            scripts = extract_scripts_from_coaching(coaching)
            colA, colB, colC = st.columns(3)
            with colA:
                if scripts.get("baseline"):
                    if st.button("â–¶ï¸ ëª¨ë²” ë‹µì•ˆ ë“£ê¸°"):
                        mp3 = synthesize_tts(scripts["baseline"])
                        if mp3: st.audio(mp3)
            with colB:
                if scripts.get("variants"):
                    if st.button("â–¶ï¸ ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ë“£ê¸°"):
                        mp3 = synthesize_tts(scripts["variants"])
                        if mp3: st.audio(mp3)
            with colC:
                custom_say = st.text_input("ì›í•˜ëŠ” ë¬¸ì¥ ì§ì ‘ ë“£ê¸°(ì„ íƒ)", value="")
                if st.button("â–¶ï¸ ìœ„ ë¬¸ì¥ ë“£ê¸°") and custom_say.strip():
                    mp3 = synthesize_tts(custom_say.strip())
                    if mp3: st.audio(mp3)

    # ë‹¤íšŒ ì½”ì¹­ ë£¨í”„
    if st.session_state["coaching_text"]:
        st.divider()
        st.markdown("### âœï¸ ë‹¤ì‹œ ì¨ë³´ê¸° â†’ ì¬ì½”ì¹­")
        revised = st.text_area("ìˆ˜ì •ì•ˆ(ì½”ì¹­ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ì‘ì„±)", height=140, key="revised_text")
        if st.button("ë‹¤ì‹œ ì½”ì¹­"):
            if st.session_state["last_topk"] is None or len(st.session_state["last_topk"]) == 0:
                st.warning("ë¨¼ì € ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            elif not revised.strip():
                st.warning("ìˆ˜ì •ì•ˆì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                top1 = st.session_state["last_topk"].iloc[0]
                msgs2 = make_messages_for_coach(top1, revised.strip(), workplace, tone, forb_prompt)
                coaching2 = call_llm(msgs2, max_output_tokens=1200, temperature=0.25)
                st.session_state["coaching_text"] = coaching2
                st.markdown("### ğŸ§‘â€ğŸ« ì¬ì½”ì¹­ ê²°ê³¼")
                st.write(coaching2)

    with st.expander("ğŸ“„ í˜„ì¬ ì„ íƒëœ ì¼€ì´ìŠ¤(Top-1)"):
        if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"]) > 0:
            top1 = st.session_state["last_topk"].iloc[0]
            st.write(f"**sheet:** {top1['sheet']} / **row:** {top1['row_index']} / **sim:** {top1['similarity']:.4f}")
            st.markdown("**ì»¨í…ìŠ¤íŠ¸**"); st.write(top1["context"])
            st.markdown("**í‘œì¤€ì‘ë‹µ**"); st.write(top1["answer"])
