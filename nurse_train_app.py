# nurse_train_app.py
import os, io, json, ast, re, time, hashlib, tempfile
from glob import glob
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd
from numpy.linalg import norm

import streamlit as st
from streamlit_chat import message
from openai import OpenAI

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)", page_icon="ğŸ©º", layout="wide")

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
client = OpenAI(api_key=OPENAI_API_KEY)

CHAT_MODEL = "gpt-4o-mini"                      # ìƒì„±/í‰ê°€/ì½”ì¹­ ê³µìš©
EMBED_OPTIONS = ["text-embedding-3-small", "text-embedding-3-large"]
DEFAULT_EMBED = "text-embedding-3-large"
DATA_DIR = "./data"
os.makedirs(DATA_DIR, exist_ok=True)

# â–¶â–¶ ê¹ƒí—ˆë¸Œì— ì˜¬ë ¤ë‘” ê¸°ë³¸ ì—‘ì…€ ê²½ë¡œ (ì›í•˜ëŠ” íŒŒì¼ëª…/ê²½ë¡œë¡œ ë°”ê¾¸ì„¸ìš”)
DEFAULT_XLS_PATH = "assets/ê°„í˜¸ì‚¬êµìœ¡_ì§ˆì˜ì‘ë‹µìë£Œ_ê·¼ë¬´ì§€ë³„.xlsx"

# =========================
# ìœ í‹¸
# =========================
def md5_of_bytes(b: bytes) -> str:
    m = hashlib.md5(); m.update(b); return m.hexdigest()

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    da, db = norm(a), norm(b)
    return float(np.dot(a, b) / (da * db)) if (da and db) else 0.0

def to_np(e): return np.array(e, dtype=np.float32)

def safe_parse_embedding(x):
    try: return json.loads(x)
    except Exception: return ast.literal_eval(x)

@st.cache_data
def _load_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()

# =========================
# ì„ë² ë”©(ìë™ ì°¨ì› ê°ì§€)
# =========================
EMBED_MODEL = DEFAULT_EMBED
EMBED_DIM: Optional[int] = None

def get_embedding(text: str) -> List[float]:
    global EMBED_DIM, EMBED_MODEL
    txt = (text or "").strip()
    if txt:
        resp = client.embeddings.create(model=EMBED_MODEL, input=txt)
        vec = resp.data[0].embedding
        if EMBED_DIM is None:
            EMBED_DIM = len(vec)  # small=1536, large=3072
        return vec
    else:
        if EMBED_DIM is None:
            resp = client.embeddings.create(model=EMBED_MODEL, input="a")
            EMBED_DIM = len(resp.data[0].embedding)
        return [0.0] * EMBED_DIM

# =========================
# ì—‘ì…€ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
# =========================
def guess_columns(df: pd.DataFrame) -> Tuple[List[str], Optional[str]]:
    cols = df.columns.tolist()
    answer_candidates = [c for c in cols if any(k in c for k in ["í‘œì¤€", "ë‹µ", "ëª¨ë²”", "response", "ì •ë‹µ", "answer"])]
    answer_col = answer_candidates[0] if answer_candidates else (cols[0] if cols else None)

    context_cols = []
    for c in cols:
        if c == answer_col: continue
        if df[c].dtype == object:
            text_ratio = (df[c].astype(str).str.len() > 0).mean()
            if text_ratio > 0.3:
                context_cols.append(c)
    if not context_cols:
        context_cols = [c for c in cols if c != answer_col][:3]
    return context_cols, answer_col

def build_context_row(row: pd.Series, context_cols: List[str], answer_col: Optional[str]) -> Dict[str, str]:
    parts = []
    for c in context_cols:
        val = str(row.get(c, "") or "").strip()
        if val:
            parts.append(f"[{c}] {val}")
    context_text = " | ".join(parts) if parts else str(row.to_dict())
    answer_text = str(row.get(answer_col, "") or "").strip() if answer_col else ""
    return {"context": context_text, "answer": answer_text}

# =========================
# ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸ ë¡œë“œ (ì„ íƒ)
# ì‹œíŠ¸ëª…: ê¸ˆê¸°í‘œí˜„ / ì—´: ê¸ˆê¸°í‘œí˜„, ì´ìœ , ëŒ€ì²´ë¬¸êµ¬
# =========================
def load_forbidden_sheet(xls_bytes: bytes) -> pd.DataFrame:
    try:
        xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        if "ê¸ˆê¸°í‘œí˜„" not in xl.sheet_names:
            return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])
        df = xl.parse("ê¸ˆê¸°í‘œí˜„").fillna("")
        needed = ["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"]
        for n in needed:
            if n not in df.columns: df[n] = ""
        return df[needed]
    except Exception:
        return pd.DataFrame(columns=["ê¸ˆê¸°í‘œí˜„","ì´ìœ ","ëŒ€ì²´ë¬¸êµ¬"])

def forbidden_as_prompt(df_forb: pd.DataFrame) -> str:
    if df_forb is None or df_forb.empty: return ""
    items = []
    for _, r in df_forb.iterrows():
        items.append(f"- ê¸ˆê¸°: {r['ê¸ˆê¸°í‘œí˜„']} | ì´ìœ : {r['ì´ìœ ']} | ëŒ€ì²´: {r['ëŒ€ì²´ë¬¸êµ¬']}")
    return "ë‹¤ìŒ ê¸ˆê¸° í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì œì‹œëœ ëŒ€ì²´ ë¬¸êµ¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:\n" + "\n".join(items)

# =========================
# ì„ë² ë”© ìºì‹œ êµ¬ì¶•/ë¡œë“œ (ì—‘ì…€ ê¸°ë°˜)
# =========================
def build_or_load_embeddings_from_excel(
    xls_bytes: bytes,
    sheet_name: Optional[str],
    context_cols: List[str],
    answer_col: Optional[str],
    embed_model_name: str
) -> pd.DataFrame:
    file_md5 = md5_of_bytes(xls_bytes)
    columns_sig = json.dumps({"context": context_cols, "answer": answer_col}, ensure_ascii=False, sort_keys=True)
    cache_name = f"embed__{embed_model_name}__{file_md5}__{(sheet_name or 'active')}__{md5_of_bytes(columns_sig.encode())}.csv"
    cache_path = os.path.join(DATA_DIR, cache_name)

    if os.path.isfile(cache_path):
        st.info(f"ğŸ“¦ ìºì‹œ ë¡œë“œ: {os.path.basename(cache_path)}")
        df = pd.read_csv(cache_path)
        df["embedding"] = df["embedding"].apply(safe_parse_embedding)
        return df

    xl = pd.ExcelFile(io.BytesIO(xls_bytes))
    if sheet_name and sheet_name in xl.sheet_names: sheets = [sheet_name]
    else: sheets = [xl.sheet_names[0]]

    rows = []
    for sh in sheets:
        tdf = xl.parse(sh).fillna("")
        for ridx, row in tdf.iterrows():
            built = build_context_row(row, context_cols, answer_col)
            context, answer = built["context"], built["answer"]
            emb = get_embedding(context)
            rows.append({"sheet": sh, "row_index": ridx, "context": context, "answer": answer, "embedding": emb})
            if (ridx % 20) == 19: time.sleep(0.05)

    df = pd.DataFrame(rows, columns=["sheet","row_index","context","answer","embedding"])
    tmp = df.copy(); tmp["embedding"] = tmp["embedding"].apply(json.dumps)
    tmp.to_csv(cache_path, index=False, encoding="utf-8-sig")
    st.success(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ â†’ {os.path.basename(cache_path)}")
    return df

@st.cache_data(show_spinner=True)
def load_precomputed_embeddings(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["embedding"] = df["embedding"].apply(safe_parse_embedding)
    return df

def pick_precomputed_cache(embed_model: str) -> Optional[str]:
    pattern = os.path.join(DATA_DIR, f"embed__{embed_model}__*.csv")
    candidates = glob(pattern)
    if not candidates:
        return None
    candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)
    return candidates[0]

# =========================
# ì¼€ì´ìŠ¤ ì¹´íƒˆë¡œê·¸ (ìë™ ì œì‹œìš©)
# =========================
TITLE_KEYS = ["í‰ê°€í•­ëª©","í•­ëª©","ì£¼ì œ","ì¼€ì´ìŠ¤","ì§ˆë¬¸","ì œëª©","ì¹´í…Œê³ ë¦¬"]

def build_catalog_from_preview(df: pd.DataFrame, answer_col: Optional[str]) -> pd.DataFrame:
    """ì—‘ì…€ ì›ë³¸ DFì—ì„œ ì¼€ì´ìŠ¤ íƒ€ì´í‹€ì„ ë½‘ì•„ ë¯¸ë¦¬ë³´ê¸° ì¹´íƒˆë¡œê·¸ ìƒì„±."""
    title_col = next((c for c in TITLE_KEYS if c in df.columns), None)
    titles, rows = [], []
    seen = set()
    for ridx, row in df.iterrows():
        if title_col and str(row.get(title_col,"")).strip():
            t = str(row[title_col]).strip()
        else:
            # íƒ€ì´í‹€ì´ ì—†ìœ¼ë©´ ë‹µë³€/ì»¨í…ìŠ¤íŠ¸ ì¼ë¶€ë¡œ ëŒ€ì²´
            base = str(row.get(answer_col,"") or "")[:30] if answer_col else ""
            if not base:
                # ì²« ë¬¸ìì—´ ì—´ì—ì„œ ì¼ë¶€
                for c in df.columns:
                    s = str(row.get(c,"") or "").strip()
                    if s:
                        base = s[:30]; break
            t = base or f"Row {ridx}"
        k = (t,)
        if k in seen: 
            continue
        seen.add(k)
        titles.append(t)
        rows.append(ridx)
    return pd.DataFrame({"case_title": titles, "row_index": rows})

def build_catalog_from_embed(df_embed: pd.DataFrame) -> pd.DataFrame:
    """ì„ë² ë”© DFë§Œ ìˆì„ ë•Œ ì»¨í…ìŠ¤íŠ¸ì—ì„œ íƒ€ì´í‹€ ì¶”ì¶œ."""
    titles, rows = [], []
    seen = set()
    for _, r in df_embed.iterrows():
        text = r["context"]
        title = None
        m = re.search(r"\[(í‰ê°€í•­ëª©|í•­ëª©|ì£¼ì œ|ì¼€ì´ìŠ¤|ì§ˆë¬¸|ì œëª©|ì¹´í…Œê³ ë¦¬)\]\s*([^|\n]+)", text)
        if m:
            title = m.group(2).strip()[:40]
        else:
            ans = (r.get("answer") or "")[:40]
            if ans:
                title = ans
            else:
                title = (text[:40] if text else f"Row {r['row_index']}")
        key = (title,)
        if key in seen: 
            continue
        seen.add(key)
        titles.append(title)
        rows.append(int(r["row_index"]))
    return pd.DataFrame({"case_title": titles, "row_index": rows})

def render_case_shelf(catalog: pd.DataFrame, label="ì¶”ì²œ ì¼€ì´ìŠ¤", max_items: int = 9) -> Optional[int]:
    """ì¹´íƒˆë¡œê·¸ë¥¼ ë²„íŠ¼ ê·¸ë¦¬ë“œë¡œ ë Œë”ë§í•˜ê³  ì„ íƒëœ row_indexë¥¼ ë°˜í™˜."""
    if catalog is None or catalog.empty:
        return None
    st.markdown(f"#### ğŸ“š {label}")
    show = catalog.head(max_items).reset_index(drop=True)
    cols = st.columns(3)
    chosen: Optional[int] = None
    for i, row in show.iterrows():
        with cols[i % 3]:
            if st.button("ğŸ”¹ " + str(row["case_title"]), key=f"case_{i}"):
                chosen = int(row["row_index"])
    with st.expander("ì „ì²´ ëª©ë¡ ë³´ê¸°"):
        st.dataframe(catalog)
    return chosen

def select_case_by_row(df_embed: pd.DataFrame, sheet: str, row_index: int) -> pd.DataFrame:
    sel = df_embed[(df_embed["sheet"]==sheet) & (df_embed["row_index"]==row_index)]
    if len(sel)==0:
        # sheetê°€ í•˜ë‚˜ë¿ì´ë©´ sheet ë¬´ì‹œ
        sel = df_embed[df_embed["row_index"]==row_index]
    if len(sel)==0:
        # ìµœí›„: ê·¸ëƒ¥ ì²« í–‰
        sel = df_embed.head(1)
    return sel.head(1).reset_index(drop=True)

# =========================
# ê²€ìƒ‰ & LLM í˜¸ì¶œ
# =========================
def search_top_k(df: pd.DataFrame, query: str, k: int = 3) -> pd.DataFrame:
    q_emb = to_np(get_embedding(query))
    if "_np_emb" not in df.columns:
        df["_np_emb"] = df["embedding"].apply(to_np)
    sims = df["_np_emb"].apply(lambda v: cosine_sim(v, q_emb))
    return df.assign(similarity=sims).sort_values("similarity", ascending=False).head(k).reset_index(drop=True)

def call_llm(messages: List[Dict[str, str]], max_output_tokens: int = 900, temperature: float = 0.3) -> str:
    resp = client.responses.create(
        model=CHAT_MODEL,
        input=messages,
        max_output_tokens=max_output_tokens,
        temperature=temperature,
    )
    try:
        parts = resp.output[0].content
        return "".join([c.text for c in parts if getattr(c, "type", "") == "output_text"]).strip() or "[ëª¨ë¸ ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤]"
    except Exception:
        return "[ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨]"

# =========================
# ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸
# =========================
def make_messages_for_answer(topk: pd.DataFrame, user_query: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    def trim(s: str, n: int = 1000): return s if len(s) <= n else s[:n] + " â€¦"
    docs = []
    for i, r in topk.iterrows():
        docs.append(
            f"[doc {i+1}] sheet={r['sheet']} | row={r['row_index']} | sim={r.get('similarity',1.0):.4f}\n"
            f"ì»¨í…ìŠ¤íŠ¸: {trim(r['context'])}\n"
            f"í‘œì¤€ì‘ë‹µ: {trim(r['answer'])}"
        )
    joined = "\n\n".join(docs)
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ ì§ë¬´ êµìœ¡ìš© í•œêµ­ì–´ ì¡°ì–¸ìì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì™€ í‘œì¤€ì‘ë‹µë§Œ ê·¼ê±°ë¡œ, "
        "í˜„ì¥ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì ˆì°¨/ë¬¸êµ¬/ì£¼ì˜ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©°, í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "")
    )
    user = (
        f"ì§ˆë¬¸: {user_query}\n\n"
        f"ì°¸ê³  ìë£Œ:\n{joined}\n\n"
        "ì¶œë ¥ í˜•ì‹:\n"
        "1) í•µì‹¬ ìš”ì§€ bullet\n2) ë‹¨ê³„/ìš°ì„ ìˆœìœ„\n3) ê¶Œì¥ ë§í•˜ê¸° ì˜ˆì‹œ\n4) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: [doc n], sheet/row"
    )
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_quiz(top1: pd.Series, user_answer: str, workplace: str, forb_prompt: str) -> List[Dict[str, str]]:
    system = (
        "ë‹¹ì‹ ì€ ê°„í˜¸ì‚¬ êµìœ¡ í‰ê°€ìì…ë‹ˆë‹¤. í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ ì •ë‹µìœ¼ë¡œ ì¸ì •í•˜ì„¸ìš”. "
        "í™˜ìì•ˆì „/ì ˆì°¨ ì •í™•ì„±/ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì ì ˆì„± ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê¸ˆê¸° í‘œí˜„ì€ ê°ì í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace} ìƒí™©ì…ë‹ˆë‹¤. "
        + (("\n" + forb_prompt) if forb_prompt else "") +
        "\në°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í”¼ë“œë°±í•˜ì„¸ìš”."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{top1['context']}

[í‘œì¤€ì‘ë‹µ]
{top1['answer']}

[í›ˆë ¨ìƒ ë‹µë³€]
{user_answer}

ìš”êµ¬ì‚¬í•­:
- ì¥ë‹¨ì  í”¼ë“œë°±(í•­ëª©ë³„)
- ì ìˆ˜(0~100)ì™€ ê·¼ê±°
- ê°œì„  ì˜ˆì‹œ ë‹µë³€(í˜„ì¥í˜•)
- ë§ˆì§€ë§‰ ì¤„: ê·¼ê±° í‘œê¸°(sheet/row)
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

def make_messages_for_coach(top1: pd.Series, user_answer: str, workplace: str, tone: str, forb_prompt: str) -> List[Dict[str, str]]:
    context = (top1["context"] or "").strip()
    standard = (top1["answer"] or "").strip()
    system = (
        "ë‹¹ì‹ ì€ ì„ìƒ í˜„ì¥ì—ì„œ ê°„í˜¸ì‚¬ì˜ í™˜ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ì½”ì¹­í•˜ëŠ” í•œêµ­ì–´ ì½”ì¹˜ì…ë‹ˆë‹¤. "
        "í‘œí˜„ì´ ë‹¬ë¼ë„ ì˜ë¯¸ê°€ ë™ë“±í•˜ë©´ í—ˆìš©í•˜ë˜, í™˜ìì•ˆì „ê³¼ ì˜ˆì ˆ(ì¡´ì¹­/ê²½ì²­/ëª…ë£Œì„±)ì„ ìµœìš°ì„  ê¸°ì¤€ìœ¼ë¡œ ì§€ë„í•˜ì„¸ìš”. "
        f"ê·¼ë¬´ì§€ëŠ” {workplace}ì´ë©° í•´ë‹¹ í™˜ê²½ì— ë§ëŠ” ì–´íœ˜/í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
        + (("\n" + forb_prompt) if forb_prompt else "") +
        "\nì¶”ì¸¡ì€ ê¸ˆì§€í•˜ë©° ì œê³µ ìë£Œ ë²”ìœ„ì—ì„œë§Œ ì§€ë„í•©ë‹ˆë‹¤."
    )
    user = f"""
[ì»¨í…ìŠ¤íŠ¸]
{context}

[í‘œì¤€ì‘ë‹µ(ê·¼ê±°)]
{standard}

[í›ˆë ¨ìƒ ì´ˆì•ˆ]
{user_answer}

ìš”êµ¬ì‚¬í•­(í•œêµ­ì–´ë¡œ {tone}):
1) ì˜í•œ ì (1~3ê°œ) â€” ìœ ì§€ ì´ìœ 
2) ê°œì„  í¬ì¸íŠ¸(2~4ê°œ) â€” ì™œ/ì–´ë–»ê²Œ
3) ëª¨ë²” ë‹µì•ˆ(Baseline Script) â€” 2~4ë¬¸ì¥
4) ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸(Variants)
   - ì§§ê³  ì •ì¤‘í•œ(1~2ë¬¸ì¥)
   - ê³µê° ê°•í™”(2~3ë¬¸ì¥)
   - ê¸´ê¸‰/ì•ˆì „ ìš°ì„ (í•„ìš”ì‹œ, 1~2ë¬¸ì¥)
5) ì•ˆì „Â·ì˜ˆì ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸(3~6ê°œ) â€” ë°˜ë“œì‹œ/ê¸ˆê¸° êµ¬ë¶„
6) ì—°ìŠµ í”„ë¡¬í”„íŠ¸(1~2ê°œ)
7) ë§ˆì§€ë§‰ ì¤„ ê·¼ê±°: sheet={top1['sheet']}, row={top1['row_index']}
"""
    return [{"role":"system","content":system},{"role":"user","content":user}]

# =========================
# TTS (ëª¨ë²”/ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ë‚­ë…)
# =========================
def synthesize_tts(text: str) -> Optional[str]:
    txt = (text or "").strip()
    if not txt: return None
    try:
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tmp_path = Path(tmp.name)
        tmp.close()
        with client.audio.speech.with_streaming_response.create(
            model="gpt-4o-mini-tts",
            voice="alloy",
            input=txt
        ) as resp:
            resp.stream_to_file(tmp_path)
        return str(tmp_path)
    except Exception as e:
        st.warning(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def extract_scripts_from_coaching(coaching_markdown: str) -> Dict[str, str]:
    text = coaching_markdown or ""
    def grab(section_title: str) -> str:
        pat = re.compile(rf"{section_title}.*?(?:\n[-*]\s.*|\n\n.+)", re.IGNORECASE|re.DOTALL)
        m = pat.search(text)
        if not m: return ""
        block = m.group(0)
        return block.strip()
    def first_para(s: str) -> str:
        s = s.strip()
        parts = re.split(r"\n\n+", s)
        return parts[0].strip() if parts else s
    baseline = first_para(grab("ëª¨ë²” ë‹µì•ˆ"))
    variants = first_para(grab("ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸"))
    return {"baseline": baseline, "variants": variants}

# =========================
# ì‚¬ì´ë“œë°”
# =========================
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    EMBED_MODEL = st.selectbox("ì„ë² ë”© ëª¨ë¸", EMBED_OPTIONS, index=EMBED_OPTIONS.index(DEFAULT_EMBED))
    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì§ˆë¬¸(í•™ìŠµ)", "í€´ì¦ˆ(í‰ê°€)", "ì½”ì¹˜(ì§€ë„)"], index=0)
    workplace = st.selectbox("ê·¼ë¬´ì§€ í”„ë¦¬ì…‹", ["ì¼ë°˜ë³‘ë™", "ì‘ê¸‰ì‹¤", "ìˆ˜ìˆ ì‹¤", "ì™¸ë˜", "ì†Œì•„ê³¼"], index=0)
    st.caption("ê·¼ë¬´ì§€ì— ë”°ë¼ ì–´íœ˜/í†¤/ìš°ì„ ìˆœìœ„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.")
    st.divider()
    uploaded = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx) â€” ì—…ë¡œë“œ ì—†ìœ¼ë©´ ê¸°ë³¸ íŒŒì¼ ìë™ ì‚¬ìš©", type=["xlsx"])
    sheet_input = st.text_input("ì‚¬ìš©í•  ì‹œíŠ¸ëª…(ë¹„ìš°ë©´ ì²« ì‹œíŠ¸)", value="")
    use_forbidden = st.toggle("ê¸ˆê¸° í‘œí˜„ ì‹œíŠ¸(ê¸ˆê¸°í‘œí˜„) ì‚¬ìš©", value=True)

# =========================
# ìƒíƒœ ì´ˆê¸°í™”
# =========================
defaults = {
    "excel_df": None, "last_topk": None, "context_cols": [], "answer_col": None,
    "coaching_text": "", "catalog": None, "active_sheet": None
}
for k, v in defaults.items():
    if k not in st.session_state: st.session_state[k] = v

# =========================
# ê¸°ë³¸ ì—‘ì…€ ìë™ ë¡œë“œ
# =========================
if uploaded is None:
    try:
        xls_bytes = _load_bytes(DEFAULT_XLS_PATH)
        st.info(f"ì—…ë¡œë“œ ì—†ìŒ â†’ ê¸°ë³¸ íŒŒì¼ ì‚¬ìš©: {DEFAULT_XLS_PATH}")
    except Exception as e:
        st.error(f"ê¸°ë³¸ ì—‘ì…€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. ({e})")
        st.stop()
else:
    xls_bytes = uploaded.getvalue()

# ê¸ˆê¸° ì‹œíŠ¸
forbidden_df = load_forbidden_sheet(xls_bytes) if use_forbidden else pd.DataFrame()
forb_prompt = forbidden_as_prompt(forbidden_df)

# =========================
# ë¯¸ë¦¬ ê³„ì‚°ëœ ì„ë² ë”© CSV ìš°ì„  ì‚¬ìš©(ìˆìœ¼ë©´)
# =========================
precomputed = pick_precomputed_cache(EMBED_MODEL)
if uploaded is None and st.session_state["excel_df"] is None and precomputed:
    st.session_state["excel_df"] = load_precomputed_embeddings(precomputed)
    st.success(f"ğŸ“¦ ì‚¬ì „ ê³„ì‚° ì„ë² ë”© ì‚¬ìš©: {os.path.basename(precomputed)}")

# =========================
# ë¯¸ë¦¬ë³´ê¸° & ì»¬ëŸ¼ ë§¤í•‘ (ì„ë² ë”© DFê°€ ì•„ì§ ì—†ì„ ë•Œë§Œ)
# =========================
if st.session_state["excel_df"] is None:
    try:
        preview_xl = pd.ExcelFile(io.BytesIO(xls_bytes))
        default_sheet = sheet_input or preview_xl.sheet_names[0]
        st.session_state["active_sheet"] = default_sheet
        preview_df = preview_xl.parse(default_sheet).fillna("")
        st.write(f"**ì‹œíŠ¸:** {default_sheet} / **í–‰:** {len(preview_df)} / **ì—´:** {len(preview_df.columns)}")
        st.dataframe(preview_df.head(8))
    except Exception as e:
        st.error(f"ì—‘ì…€ ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: {e}")
        st.stop()

    # ì»¬ëŸ¼ ë§¤í•‘
    st.subheader("ğŸ§© ì»¬ëŸ¼ ë§¤í•‘")
    cols = preview_df.columns.tolist()
    if not st.session_state["context_cols"] and not st.session_state["answer_col"]:
        g_ctx, g_ans = guess_columns(preview_df)
        st.session_state["context_cols"] = g_ctx
        st.session_state["answer_col"] = g_ans

    sel_ctx = st.multiselect("ì»¨í…ìŠ¤íŠ¸ë¡œ í•©ì¹  ì—´ë“¤", cols, default=[c for c in st.session_state["context_cols"] if c in cols])
    sel_ans = st.selectbox("í‘œì¤€ì‘ë‹µ(ì •ë‹µ) ì—´", ["<ì„ íƒ ì•ˆ í•¨>"] + cols,
                        index=(0 if (st.session_state["answer_col"] not in cols) else (cols.index(st.session_state["answer_col"]) + 1)))
    st.caption("í‘œì¤€ì‘ë‹µ ì—´ì„ ì§€ì •í•˜ë©´ í‰ê°€/ì½”ì¹˜ í’ˆì§ˆì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")

    if st.button("ì´ ë§¤í•‘ìœ¼ë¡œ ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ"):
        try:
            df_embed = build_or_load_embeddings_from_excel(
                xls_bytes=xls_bytes,
                sheet_name=(sheet_input or None),
                context_cols=sel_ctx if sel_ctx else cols[:3],
                answer_col=(None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans),
                embed_model_name=EMBED_MODEL
            )
            st.session_state["excel_df"] = df_embed
            st.session_state["context_cols"] = sel_ctx if sel_ctx else cols[:3]
            st.session_state["answer_col"] = (None if sel_ans == "<ì„ íƒ ì•ˆ í•¨>" else sel_ans)
            st.session_state["active_sheet"] = default_sheet
            st.success("ì„ë² ë”© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ì„ë² ë”© ì¤€ë¹„ ì‹¤íŒ¨: {e}")

df_embed = st.session_state["excel_df"]
if df_embed is None:
    st.info("ë¨¼ì € **ì„ë² ë”© ìºì‹œ ìƒì„±/ë¡œë“œ**ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    st.stop()

# ì¹´íƒˆë¡œê·¸ ë§Œë“¤ê¸° (ìë™ ì œì‹œìš©)
if uploaded is None or 'preview_df' not in locals():
    # ì„ë² ë”© DFì—ì„œ ì¶”ì¶œ
    st.session_state["catalog"] = build_catalog_from_embed(df_embed)
else:
    st.session_state["catalog"] = build_catalog_from_preview(preview_df, st.session_state["answer_col"])

catalog = st.session_state["catalog"]

st.divider()
st.title("ğŸ©º ê°„í˜¸ì‚¬ êµìœ¡ìš© ì±—ë´‡ (Excel RAG + Coach)")

# =========================
# ê³µí†µ: ì¼€ì´ìŠ¤ ìë™ ì œì‹œ(ì—†ìœ¼ë©´ ëœë¤)
# =========================
def ensure_case_selected():
    if st.session_state["last_topk"] is None:
        if catalog is not None and not catalog.empty:
            pick_row = int(catalog.sample(1)["row_index"].iloc[0])
            sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
            st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, pick_row)
            st.info(f"ìë™ ì œì‹œëœ ì¼€ì´ìŠ¤: {catalog[catalog['row_index']==pick_row]['case_title'].iloc[0]}")

def show_case_header(top1: pd.Series):
    st.markdown("### ğŸ“„ ì¼€ì´ìŠ¤ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**ì»¨í…ìŠ¤íŠ¸**")
        st.write(top1["context"])
    with c2:
        st.markdown("**í‘œì¤€ì‘ë‹µ**")
        st.write(top1["answer"])

# =========================
# ëª¨ë“œë³„ UI
# =========================
if mode == "ì§ˆë¬¸(í•™ìŠµ)":
    with st.form("ask_form", clear_on_submit=True):
        q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 'í™˜ì í™•ì¸ ì ˆì°¨ëŠ”?')", "")
        send = st.form_submit_button("Send")
    if send and q.strip():
        topk = search_top_k(df_embed, q.strip(), k=3)
        st.session_state["last_topk"] = topk
        msgs = make_messages_for_answer(topk, q.strip(), workplace, forb_prompt)
        ans = call_llm(msgs)
        message(q.strip(), is_user=True, key="ask_u_"+str(time.time()))
        message(ans, key="ask_b_"+str(time.time()))
    with st.expander("ğŸ” ì‚¬ìš©ëœ ìë£Œ(Top-K)"):
        if st.session_state["last_topk"] is not None:
            st.dataframe(st.session_state["last_topk"][["sheet","row_index","similarity","context","answer"]])

elif mode == "í€´ì¦ˆ(í‰ê°€)":
    # ìë™ ì œì‹œ
    ensure_case_selected()
    # ì¹´íƒˆë¡œê·¸ ê·¸ë¦¬ë“œ (ì›í´ë¦­ ì„ íƒ)
    chosen = render_case_shelf(catalog, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", max_items=9)
    if chosen is not None:
        sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
        st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, chosen)

    if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"])>0:
        top1 = st.session_state["last_topk"].iloc[0]
        show_case_header(top1)

        st.caption("ì¼€ì´ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ í›ˆë ¨ìƒ ë‹µë³€ì„ í‰ê°€í•©ë‹ˆë‹¤.")
        with st.form("quiz_form", clear_on_submit=False):
            user_answer = st.text_area("í›ˆë ¨ìƒ ë‹µë³€", height=180)
            btn_eval = st.form_submit_button("í‰ê°€ ìš”ì²­")
        if btn_eval:
            msgs = make_messages_for_quiz(top1, (user_answer or "").strip(), workplace, forb_prompt)
            feedback = call_llm(msgs)
            st.markdown("### ğŸ§ª í‰ê°€ ê²°ê³¼")
            st.write(feedback)
    else:
        st.warning("ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì„ë² ë”©ì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")

else:  # ì½”ì¹˜(ì§€ë„)
    # ìë™ ì œì‹œ
    ensure_case_selected()
    # ì¹´íƒˆë¡œê·¸ ê·¸ë¦¬ë“œ (ì›í´ë¦­ ì„ íƒ)
    chosen = render_case_shelf(catalog, label="ë‹¤ë¥¸ ì¼€ì´ìŠ¤ ì„ íƒ", max_items=9)
    if chosen is not None:
        sheet = st.session_state.get("active_sheet") or str(df_embed["sheet"].iloc[0])
        st.session_state["last_topk"] = select_case_by_row(df_embed, sheet, chosen)

    # ì´ˆì•ˆ ìƒíƒœ ë³´ê´€
    if "draft_text" not in st.session_state:
        st.session_state["draft_text"] = ""

    if st.session_state["last_topk"] is not None and len(st.session_state["last_topk"])>0:
        top1 = st.session_state["last_topk"].iloc[0]
        show_case_header(top1)

        st.caption("í›ˆë ¨ìƒì˜ ì´ˆì•ˆ ë¬¸ì¥ì„ ì½”ì¹­í•˜ì—¬ ë” ì˜ˆì˜ ë°”ë¥´ê³  ì•ˆì „í•œ ë¬¸ì¥ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.")
        with st.form("coach_form", clear_on_submit=False):
            tone = st.selectbox("ì½”ì¹­ í†¤", ["ë”°ëœ»í•˜ê³  ì •ì¤‘í•˜ê²Œ","ê°„ê²°í•˜ê³  ë‹¨í˜¸í•˜ê²Œ","ì°¨ë¶„í•˜ê³  ê³µê° ìˆê²Œ"], index=0)
            user_answer = st.text_area("í›ˆë ¨ìƒ ì´ˆì•ˆ(í˜„ì¬ ë§í•˜ë ¤ëŠ” ë¬¸ì¥)", value=st.session_state["draft_text"], height=140, key="draft_area")
            colA, colB = st.columns(2)
            with colA:
                auto_draft = st.form_submit_button("ì´ˆì•ˆ ìë™ ì œì‹œ")
            with colB:
                btn_coach = st.form_submit_button("ì½”ì¹­ ë°›ê¸°")

        if auto_draft:
            # í‘œì¤€ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ì§§ì€ ì •ì¤‘ ìŠ¤í¬ë¦½íŠ¸ ì œì•ˆ
            msgs_draft = [
                {"role":"system","content":f"ê°„í˜¸ì‚¬ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì½”ì¹˜ì…ë‹ˆë‹¤. ê·¼ë¬´ì§€: {workplace}. í‘œì¤€ì‘ë‹µì„ ì°¸ê³ í•´ í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥ ì •ì¤‘í•œ ì•ˆë‚´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”."},
                {"role":"user","content": f"[í‘œì¤€ì‘ë‹µ]\n{top1['answer']}\n\nì¶œë ¥: ê³µì†í•˜ê³  ëª…í™•í•œ 1~2ë¬¸ì¥"}
            ]
            draft_text = call_llm(msgs_draft, max_output_tokens=200, temperature=0.2)
            st.session_state["draft_text"] = draft_text
            st.experimental_rerun()

        if btn_coach:
            msgs = make_messages_for_coach(top1, (st.session_state["draft_text"] or "").strip() or (user_answer or "").strip(), workplace, tone, forb_prompt)
            coaching = call_llm(msgs, max_output_tokens=1200, temperature=0.25)
            st.session_state["coaching_text"] = coaching
            st.markdown("### ğŸ§‘â€ğŸ« ì½”ì¹­ ê²°ê³¼")
            st.write(coaching)

            # --- TTS ë²„íŠ¼ë“¤ ---
            scripts = extract_scripts_from_coaching(coaching)
            col1, col2, col3 = st.columns(3)
            with col1:
                if scripts.get("baseline"):
                    if st.button("â–¶ï¸ ëª¨ë²” ë‹µì•ˆ ë“£ê¸°"):
                        mp3 = synthesize_tts(scripts["baseline"])
                        if mp3: st.audio(mp3)
            with col2:
                if scripts.get("variants"):
                    if st.button("â–¶ï¸ ëŒ€ì•ˆ ìŠ¤í¬ë¦½íŠ¸ ë“£ê¸°"):
                        mp3 = synthesize_tts(scripts["variants"])
                        if mp3: st.audio(mp3)
            with col3:
                custom_say = st.text_input("ì›í•˜ëŠ” ë¬¸ì¥ ì§ì ‘ ë“£ê¸°(ì„ íƒ)", value="")
                if st.button("â–¶ï¸ ìœ„ ë¬¸ì¥ ë“£ê¸°") and custom_say.strip():
                    mp3 = synthesize_tts(custom_say.strip())
                    if mp3: st.audio(mp3)

        # ì¬ì½”ì¹­ ë£¨í”„
        if st.session_state["coaching_text"]:
            st.divider()
            st.markdown("### âœï¸ ë‹¤ì‹œ ì¨ë³´ê¸° â†’ ì¬ì½”ì¹­")
            revised = st.text_area("ìˆ˜ì •ì•ˆ(ì½”ì¹­ì„ ë°˜ì˜í•´ ë‹¤ì‹œ ì‘ì„±)", height=140, key="revised_text")
            if st.button("ë‹¤ì‹œ ì½”ì¹­"):
                msgs2 = make_messages_for_coach(top1, (revised or "").strip(), workplace, tone, forb_prompt)
                coaching2 = call_llm(msgs2, max_output_tokens=1200, temperature=0.25)
                st.session_state["coaching_text"] = coaching2
                st.markdown("### ğŸ§‘â€ğŸ« ì¬ì½”ì¹­ ê²°ê³¼")
                st.write(coaching2)
    else:
        st.warning("ì¼€ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì„ë² ë”©ì„ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.")
